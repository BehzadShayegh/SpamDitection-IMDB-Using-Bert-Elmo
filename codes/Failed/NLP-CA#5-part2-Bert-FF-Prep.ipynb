{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"NLP-CA#5-part2-Bert-FF-Prep.ipynb","provenance":[{"file_id":"1Y7-s_TWyNeWnuNl0k44yykU-pURXuCBV","timestamp":1588957710140},{"file_id":"1VuZcbezljhvTdPrEdLVEbQFZ31zQWNXO","timestamp":1588877020091},{"file_id":"1JdL9q3iGekwNzxZeNJdlY092cNUCDRvZ","timestamp":1588867302500},{"file_id":"1XFJsydGgcCx_GspaoqQdJB_PVukTD8lI","timestamp":1588599657507}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"bf3ff2347b004c7eb5f686458d15363d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_3b9b6f3ec5b843ea9669425dd63fabef","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_77004e24cd54424eabb122da5aafd997","IPY_MODEL_070d07e6e59442c8bebe673af06a8557"]}},"3b9b6f3ec5b843ea9669425dd63fabef":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"77004e24cd54424eabb122da5aafd997":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_c662ed8245a144e9ac58a15b0d6c5b22","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":25000,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":25000,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c5cc6b0a453b4912b9bf2466b245e95f"}},"070d07e6e59442c8bebe673af06a8557":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_572787e30e59465a9680033d89c6b2ff","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 25000/25000 [04:57&lt;00:00, 84.13it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f534fd5e422a4350b9e8b22ee829fa1e"}},"c662ed8245a144e9ac58a15b0d6c5b22":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"c5cc6b0a453b4912b9bf2466b245e95f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"572787e30e59465a9680033d89c6b2ff":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"f534fd5e422a4350b9e8b22ee829fa1e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f6adfaa30eed40fabe6a18272701f774":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_91552784d802480ba9f4f83fcd83f0c2","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_0e6c17f4b7204d12bd501618f25ffc46","IPY_MODEL_26b7d8272f984475996f66bd103b62db"]}},"91552784d802480ba9f4f83fcd83f0c2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0e6c17f4b7204d12bd501618f25ffc46":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_e412509d4af44f5aad91f74d49c8c4f2","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":25000,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":25000,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_3d9322a55a3640f191bd61ae1cf2a976"}},"26b7d8272f984475996f66bd103b62db":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_cc0018e7676c4428a8a7c6b82ac4194f","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 25000/25000 [02:27&lt;00:00, 169.37it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e1cdbe76e8874757a735765f5cd5b013"}},"e412509d4af44f5aad91f74d49c8c4f2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"3d9322a55a3640f191bd61ae1cf2a976":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"cc0018e7676c4428a8a7c6b82ac4194f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"e1cdbe76e8874757a735765f5cd5b013":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c51d78852bdc428caa1316974989bbc6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_ecd22248ccc4495a9f398094f816c697","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_c338f4f643434aef872d45ad445a99d8","IPY_MODEL_04ab4a21f1554a0f9c10a6fb5ea16591"]}},"ecd22248ccc4495a9f398094f816c697":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c338f4f643434aef872d45ad445a99d8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_705c8626810a464db4432c273880741c","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":25000,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":25000,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a59ae1dc2bee403db5d9967180b09742"}},"04ab4a21f1554a0f9c10a6fb5ea16591":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_578eb4ee6292492bb863655cbd440dcf","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 25000/25000 [01:58&lt;00:00, 210.55it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_81097238549c476d976805d2e56a634c"}},"705c8626810a464db4432c273880741c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"a59ae1dc2bee403db5d9967180b09742":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"578eb4ee6292492bb863655cbd440dcf":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"81097238549c476d976805d2e56a634c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"40582b16d9cc4c62957063d92a94e96d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_83782bb5fe964dd4a9ab3079f96891af","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_45e918dd4f0c42b3ba7c8c8dc8c1e310","IPY_MODEL_e6d2c6a146594cd89f05aa22b4b9411b"]}},"83782bb5fe964dd4a9ab3079f96891af":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"45e918dd4f0c42b3ba7c8c8dc8c1e310":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_acc177ee273d4b82a75b0e0a348b9b44","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":25000,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":25000,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c7a724ab3237451dbe7cb6cf00914a57"}},"e6d2c6a146594cd89f05aa22b4b9411b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_9c24d488c13a483e9f12bb8fe96bc218","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 25000/25000 [01:08&lt;00:00, 365.91it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_4e63572321a945ae8684dbdfb216dd84"}},"acc177ee273d4b82a75b0e0a348b9b44":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"c7a724ab3237451dbe7cb6cf00914a57":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9c24d488c13a483e9f12bb8fe96bc218":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"4e63572321a945ae8684dbdfb216dd84":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"id":"LlcEljcR2cCe","colab_type":"code","outputId":"e45d4f91-4715-4726-9e9d-a7a8de223415","executionInfo":{"status":"ok","timestamp":1588958562855,"user_tz":-270,"elapsed":5797,"user":{"displayName":"Aref Afzali","photoUrl":"","userId":"04593065310074929856"}},"colab":{"base_uri":"https://localhost:8080/","height":341}},"source":["import tensorflow.compat.v1 as tf\n","!pip install transformers\n","tf.disable_eager_execution()\n","tf.test.gpu_device_name()"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (2.9.0)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.86)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.4)\n","Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n","Requirement already satisfied: tokenizers==0.7.0 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.9)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.4.5.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["'/device:GPU:0'"]},"metadata":{"tags":[]},"execution_count":1}]},{"cell_type":"code","metadata":{"id":"U2vMZhwyVEQI","colab_type":"code","colab":{}},"source":["import os\n","import urllib.request\n","import tarfile\n","\n","urllib.request.urlretrieve('http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz', 'dataset.gz')\n","with tarfile.open('dataset.gz', 'r:gz') as tar:\n","    tar.extractall()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"csvoNaOXQ5-b","colab_type":"code","colab":{}},"source":["path = \"aclImdb/{}/{}/\"\n","trainfils, testfils = [], []\n","for g,collection in {'train': trainfils, 'test': testfils}.items() :\n","  for i,p in enumerate(['neg','pos']) :\n","    folder = path.format(g,p)\n","    for name in os.listdir(folder) :\n","      record = {\n","          'name' : name,\n","          'text' : open(folder+name).read(),\n","          'label' : i\n","      }\n","      collection.append(record)\n","\n","import pandas as pd\n","\n","train_df = pd.DataFrame(trainfils)\n","test_df = pd.DataFrame(testfils)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vuqp9PBl_8zt","colab_type":"code","outputId":"6daa8372-6149-4417-89d6-ab8c7d5cf8c1","executionInfo":{"status":"ok","timestamp":1588958895875,"user_tz":-270,"elapsed":337632,"user":{"displayName":"Aref Afzali","photoUrl":"","userId":"04593065310074929856"}},"colab":{"base_uri":"https://localhost:8080/","height":189,"referenced_widgets":["bf3ff2347b004c7eb5f686458d15363d","3b9b6f3ec5b843ea9669425dd63fabef","77004e24cd54424eabb122da5aafd997","070d07e6e59442c8bebe673af06a8557","c662ed8245a144e9ac58a15b0d6c5b22","c5cc6b0a453b4912b9bf2466b245e95f","572787e30e59465a9680033d89c6b2ff","f534fd5e422a4350b9e8b22ee829fa1e","f6adfaa30eed40fabe6a18272701f774","91552784d802480ba9f4f83fcd83f0c2","0e6c17f4b7204d12bd501618f25ffc46","26b7d8272f984475996f66bd103b62db","e412509d4af44f5aad91f74d49c8c4f2","3d9322a55a3640f191bd61ae1cf2a976","cc0018e7676c4428a8a7c6b82ac4194f","e1cdbe76e8874757a735765f5cd5b013"]}},"source":["import pandas as pd\n","import numpy as np\n","import nltk\n","from nltk.tokenize import RegexpTokenizer\n","from nltk.corpus import stopwords\n","from tqdm.notebook import tqdm\n","import re\n","nltk.download('punkt')\n","nltk.download('stopwords')\n","tokenizer = RegexpTokenizer(r'\\w+')\n","tqdm.pandas()\n","\n","def cleanhtml(raw_html):\n","  cleanr = re.compile('<.*?>')\n","  cleantext = re.sub(cleanr, '', raw_html)\n","  return cleantext\n","\n","MAX_LEN = 128\n","def make_clean(s) :\n","  s = cleanhtml(s)\n","  for i in range(10) :\n","    s = s.replace(str(i), ' ')\n","  tokens = np.array(tokenizer.tokenize(s.lower()))\n","  tokens = tokens[~np.isin(tokens, stopwords.words())]\n","  return ' '.join(tokens)\n","\n","train_df['clean'] = train_df['text'].progress_apply(make_clean)\n","test_df['clean'] = test_df['text'].progress_apply(make_clean)"],"execution_count":4,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bf3ff2347b004c7eb5f686458d15363d","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=25000.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f6adfaa30eed40fabe6a18272701f774","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=25000.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ifosW9VhVV3H","colab_type":"code","outputId":"c4fcfe0f-316d-4828-eb69-eb9c4fd3e796","executionInfo":{"status":"ok","timestamp":1588959028017,"user_tz":-270,"elapsed":469409,"user":{"displayName":"Aref Afzali","photoUrl":"","userId":"04593065310074929856"}},"colab":{"base_uri":"https://localhost:8080/","height":117,"referenced_widgets":["c51d78852bdc428caa1316974989bbc6","ecd22248ccc4495a9f398094f816c697","c338f4f643434aef872d45ad445a99d8","04ab4a21f1554a0f9c10a6fb5ea16591","705c8626810a464db4432c273880741c","a59ae1dc2bee403db5d9967180b09742","578eb4ee6292492bb863655cbd440dcf","81097238549c476d976805d2e56a634c","40582b16d9cc4c62957063d92a94e96d","83782bb5fe964dd4a9ab3079f96891af","45e918dd4f0c42b3ba7c8c8dc8c1e310","e6d2c6a146594cd89f05aa22b4b9411b","acc177ee273d4b82a75b0e0a348b9b44","c7a724ab3237451dbe7cb6cf00914a57","9c24d488c13a483e9f12bb8fe96bc218","4e63572321a945ae8684dbdfb216dd84"]}},"source":["from transformers import BertTokenizer\n","btokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n","\n","MAX_LEN = 128\n","for df in [train_df,test_df] :\n","    input_ids = []\n","    attention_masks = []\n","\n","    for sent in tqdm(df['clean']):\n","        encoded_dict = btokenizer.encode_plus(\n","                            sent,\n","                            add_special_tokens = True,\n","                            max_length = MAX_LEN,\n","                            pad_to_max_length = True,\n","                            return_attention_mask = True,\n","                            return_tensors = 'pt',\n","                      )\n","        input_ids.append(encoded_dict['input_ids'])\n","        attention_masks.append(encoded_dict['attention_mask'])\n","\n","    df['input_ids'] = input_ids\n","    df['attention_masks'] = attention_masks"],"execution_count":5,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c51d78852bdc428caa1316974989bbc6","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=25000.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"40582b16d9cc4c62957063d92a94e96d","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=25000.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1ydle9gnRwjr","colab_type":"code","outputId":"5f3072cc-86ca-4d3b-d979-8ca2a6383621","executionInfo":{"status":"ok","timestamp":1588959028019,"user_tz":-270,"elapsed":468930,"user":{"displayName":"Aref Afzali","photoUrl":"","userId":"04593065310074929856"}},"colab":{"base_uri":"https://localhost:8080/","height":204}},"source":["train_df.head()"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>name</th>\n","      <th>text</th>\n","      <th>label</th>\n","      <th>clean</th>\n","      <th>input_ids</th>\n","      <th>attention_masks</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>7735_1.txt</td>\n","      <td>The funny sound that you may hear when you eye...</td>\n","      <td>0</td>\n","      <td>funny sound may hear eyeball execrable version...</td>\n","      <td>[[tensor(101), tensor(6057), tensor(2614), ten...</td>\n","      <td>[[tensor(1), tensor(1), tensor(1), tensor(1), ...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>10311_3.txt</td>\n","      <td>SPOILER ALERT In this generic and forgettable ...</td>\n","      <td>0</td>\n","      <td>spoiler alert generic forgettable action movie...</td>\n","      <td>[[tensor(101), tensor(27594), tensor(2121), te...</td>\n","      <td>[[tensor(1), tensor(1), tensor(1), tensor(1), ...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>6264_2.txt</td>\n","      <td>Nightmare Weekend is proof positive that some ...</td>\n","      <td>0</td>\n","      <td>nightmare weekend proof positive people desper...</td>\n","      <td>[[tensor(101), tensor(10103), tensor(5353), te...</td>\n","      <td>[[tensor(1), tensor(1), tensor(1), tensor(1), ...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>11383_2.txt</td>\n","      <td>This is a truly awful \"B\" movie. It is witless...</td>\n","      <td>0</td>\n","      <td>truly awful b movie witless often embarrassing...</td>\n","      <td>[[tensor(101), tensor(5621), tensor(9643), ten...</td>\n","      <td>[[tensor(1), tensor(1), tensor(1), tensor(1), ...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>12149_4.txt</td>\n","      <td>Set in Providence, Rhode Island, Feeding the M...</td>\n","      <td>0</td>\n","      <td>set providence rhode island feeding masses tri...</td>\n","      <td>[[tensor(101), tensor(2275), tensor(11293), te...</td>\n","      <td>[[tensor(1), tensor(1), tensor(1), tensor(1), ...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["          name  ...                                    attention_masks\n","0   7735_1.txt  ...  [[tensor(1), tensor(1), tensor(1), tensor(1), ...\n","1  10311_3.txt  ...  [[tensor(1), tensor(1), tensor(1), tensor(1), ...\n","2   6264_2.txt  ...  [[tensor(1), tensor(1), tensor(1), tensor(1), ...\n","3  11383_2.txt  ...  [[tensor(1), tensor(1), tensor(1), tensor(1), ...\n","4  12149_4.txt  ...  [[tensor(1), tensor(1), tensor(1), tensor(1), ...\n","\n","[5 rows x 6 columns]"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"hAPU3BMfxF3O","colab_type":"code","colab":{}},"source":["import tensorflow_hub as hub\n","from tensorflow.compat.v1.keras import backend as K\n","# https://github.com/strongio/keras-bert/blob/master/keras-bert.ipynb\n","class BertLayer(tf.keras.layers.Layer):\n","    def __init__(\n","        self,\n","        n_fine_tune_layers=10,\n","        pooling=\"first\",\n","        bert_path=\"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\",\n","        **kwargs,\n","    ):\n","        self.n_fine_tune_layers = n_fine_tune_layers\n","        self.trainable = True\n","        self.output_size = 768\n","        self.pooling = pooling\n","        self.bert_path = bert_path\n","        if self.pooling not in [\"first\", \"mean\"]:\n","            raise NameError(\n","                f\"Undefined pooling type (must be either first or mean, but is {self.pooling}\"\n","            )\n","\n","        super(BertLayer, self).__init__(**kwargs)\n","\n","    def build(self, input_shape):\n","        self.bert = hub.Module(\n","            self.bert_path, trainable=self.trainable, name=f\"{self.name}_module\"\n","        )\n","\n","        # Remove unused layers\n","        trainable_vars = self.bert.variables\n","        if self.pooling == \"first\":\n","            trainable_vars = [var for var in trainable_vars if not \"/cls/\" in var.name]\n","            trainable_layers = [\"pooler/dense\"]\n","\n","        elif self.pooling == \"mean\":\n","            trainable_vars = [\n","                var\n","                for var in trainable_vars\n","                if not \"/cls/\" in var.name and not \"/pooler/\" in var.name\n","            ]\n","            trainable_layers = []\n","        else:\n","            raise NameError(\n","                f\"Undefined pooling type (must be either first or mean, but is {self.pooling}\"\n","            )\n","\n","        # Select how many layers to fine tune\n","        for i in range(self.n_fine_tune_layers):\n","            trainable_layers.append(f\"encoder/layer_{str(11 - i)}\")\n","\n","        # Update trainable vars to contain only the specified layers\n","        trainable_vars = [\n","            var\n","            for var in trainable_vars\n","            if any([l in var.name for l in trainable_layers])\n","        ]\n","\n","        # Add to trainable weights\n","        for var in trainable_vars:\n","            self._trainable_weights.append(var)\n","\n","        for var in self.bert.variables:\n","            if var not in self._trainable_weights:\n","                self._non_trainable_weights.append(var)\n","\n","        super(BertLayer, self).build(input_shape)\n","\n","    def call(self, inputs):\n","        inputs = [K.cast(x, dtype=\"int32\") for x in inputs]\n","        input_ids, input_mask, segment_ids = inputs\n","        bert_inputs = dict(\n","            input_ids=input_ids, input_mask=input_mask, segment_ids=segment_ids\n","        )\n","        if self.pooling == \"first\":\n","            pooled = self.bert(inputs=bert_inputs, signature=\"tokens\", as_dict=True)[\n","                \"pooled_output\"\n","            ]\n","        elif self.pooling == \"mean\":\n","            result = self.bert(inputs=bert_inputs, signature=\"tokens\", as_dict=True)[\n","                \"sequence_output\"\n","            ]\n","\n","            mul_mask = lambda x, m: x * tf.expand_dims(m, axis=-1)\n","            masked_reduce_mean = lambda x, m: tf.reduce_sum(mul_mask(x, m), axis=1) / (\n","                    tf.reduce_sum(m, axis=1, keepdims=True) + 1e-10)\n","            input_mask = tf.cast(input_mask, tf.float32)\n","            pooled = masked_reduce_mean(result, input_mask)\n","        else:\n","            raise NameError(f\"Undefined pooling type (must be either first or mean, but is {self.pooling}\")\n","\n","        return pooled\n","\n","    def compute_output_shape(self, input_shape):\n","        return (input_shape[0], self.output_size)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XOT8afgW4CW-","colab_type":"code","outputId":"dad3559c-1666-4a8e-8dca-c3c9cd0cf562","executionInfo":{"status":"ok","timestamp":1588959037432,"user_tz":-270,"elapsed":477533,"user":{"displayName":"Aref Afzali","photoUrl":"","userId":"04593065310074929856"}},"colab":{"base_uri":"https://localhost:8080/","height":595}},"source":["from tensorflow.compat.v1.keras import layers\n","from tensorflow.compat.v1.keras.models import Model\n","from tensorflow.compat.v1.keras.optimizers import Adam\n","\n","input_ids = layers.Input(shape=(MAX_LEN,), dtype=tf.int32, name=\"input_ids\")\n","input_mask = layers.Input(shape=(MAX_LEN,), dtype=tf.int32, name=\"input_mask\")\n","segment_ids = layers.Input(shape=(MAX_LEN,), dtype=tf.int32, name=\"segment_ids\")\n","bert_inputs = [input_ids, input_mask, segment_ids]\n","bert_output = BertLayer(n_fine_tune_layers=10, pooling=\"first\")(bert_inputs)\n","dense = layers.Dense(768, activation='relu')(bert_output)\n","pred = layers.Dense(1, activation='sigmoid')(dense)\n","model = Model(inputs=bert_inputs, outputs=pred)\n","model.compile(loss='binary_crossentropy', optimizer=Adam(lr=2e-4), metrics=['accuracy'])\n","model.summary()"],"execution_count":8,"outputs":[{"output_type":"stream","text":["INFO:absl:Using /tmp/tfhub_modules to cache modules.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:1666: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n","Instructions for updating:\n","If using Keras pass *_constraint arguments to layers.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:1666: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n","Instructions for updating:\n","If using Keras pass *_constraint arguments to layers.\n"],"name":"stderr"},{"output_type":"stream","text":["Model: \"model\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_ids (InputLayer)          [(None, 128)]        0                                            \n","__________________________________________________________________________________________________\n","input_mask (InputLayer)         [(None, 128)]        0                                            \n","__________________________________________________________________________________________________\n","segment_ids (InputLayer)        [(None, 128)]        0                                            \n","__________________________________________________________________________________________________\n","bert_layer (BertLayer)          (None, 768)          110104890   input_ids[0][0]                  \n","                                                                 input_mask[0][0]                 \n","                                                                 segment_ids[0][0]                \n","__________________________________________________________________________________________________\n","dense (Dense)                   (None, 768)          590592      bert_layer[0][0]                 \n","__________________________________________________________________________________________________\n","dense_1 (Dense)                 (None, 1)            769         dense[0][0]                      \n","==================================================================================================\n","Total params: 110,696,251\n","Trainable params: 72,060,673\n","Non-trainable params: 38,635,578\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"otnALpexNEO-","colab_type":"code","colab":{}},"source":["from tensorflow.compat.v1 import keras\n","\n","session = keras.backend.get_session()\n","init = tf.global_variables_initializer()\n","session.run(init)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"aF1FxPD5WeeO","colab_type":"code","colab":{}},"source":["import numpy as np\n","import sklearn.metrics as sklm\n","from tensorflow.compat.v1 import keras\n","\n","class Metrics(keras.callbacks.Callback):\n","    def __init__(self, val_data, batch_size = 32) :\n","        super().__init__()\n","        self.validation_data = val_data\n","        self.batch_size = batch_size\n","\n","    def on_train_begin(self, logs={}):\n","        self.loss = []\n","        self.precision = []\n","        self.recall = []\n","        self.f1s = []\n","        self.accuracy = []\n","        self.auc = []\n","\n","    def on_epoch_end(self, epoch, logs={}):\n","        score = np.asarray(self.model.predict(self.validation_data[0]))\n","        predict = np.squeeze(score.round()).reshape(-1)\n","        targ = self.validation_data[1]\n","        self.loss.append(logs['val_loss'])\n","        self.auc.append(sklm.roc_auc_score(targ, score))\n","        self.precision.append(sklm.precision_score(targ, predict))\n","        self.recall.append(sklm.recall_score(targ, predict))\n","        self.f1s.append(sklm.f1_score(targ, predict))\n","        self.accuracy.append(sklm.accuracy_score(targ, predict))\n","\n","        pd.DataFrame({\n","            'loss': self.loss,\n","            'precision': self.precision,\n","            'recall': self.recall,\n","            'f1s': self.f1s,\n","            'accuracy': self.accuracy,\n","            'auc': self.auc\n","        }).to_csv('recors.csv')\n","\n","        return"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"fO1Z03SOlc5D","colab_type":"code","colab":{}},"source":["import numpy as np\n","\n","# Create datasets (Only take up to MAX_LEN words)\n","train_ids = train_df['input_ids'].tolist()\n","train_ids = [t.tolist()[0:MAX_LEN] for t in train_ids]\n","train_ids = np.array(train_ids, dtype=int)[:, np.newaxis].reshape(train_df.shape[0],-1)\n","train_masks = train_df['attention_masks'].tolist()\n","train_masks = [t.tolist()[0:MAX_LEN] for t in train_masks]\n","train_masks = np.array(train_masks, dtype=int)[:, np.newaxis].reshape(train_df.shape[0],-1)\n","train_label = train_df['label'].tolist()\n","\n","test_ids = test_df['input_ids'].tolist()\n","test_ids = [t.tolist()[0:MAX_LEN] for t in test_ids]\n","test_ids = np.array(test_ids, dtype=int)[:, np.newaxis].reshape(test_df.shape[0],-1)\n","test_masks = test_df['attention_masks'].tolist()\n","test_masks = [t.tolist()[0:MAX_LEN] for t in test_masks]\n","test_masks = np.array(test_masks, dtype=int)[:, np.newaxis].reshape(test_df.shape[0],-1)\n","test_label = test_df['label'].tolist()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6MGKzKb7mHFE","colab_type":"code","colab":{}},"source":["# tf.compat.v1.experimental.output_all_intermediates(True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"lO8xmZ4R4CUc","colab_type":"code","outputId":"6df6bebe-c8e6-4d24-8c76-05b7b3811e88","executionInfo":{"status":"error","timestamp":1588962366493,"user_tz":-270,"elapsed":3804582,"user":{"displayName":"Aref Afzali","photoUrl":"","userId":"04593065310074929856"}},"colab":{"base_uri":"https://localhost:8080/","height":720}},"source":["  # def variable_created_in_scope(self, v):\n","  #   if not hasattr(v, '_distribute_strategy'):\n","  #     v._distribute_strategy = None\n","  #   return v._distribute_strategy is None  # pylint: disable=protected-access\n","#==============================================================================================\n","metrics = Metrics(([test_ids, test_masks, np.zeros(test_ids.shape)], test_label))\n","\n","model.fit([train_ids, train_masks, np.zeros(train_ids.shape)], \n","          train_label,\n","          validation_data=([test_ids, test_masks, np.zeros(test_ids.shape)], test_label),\n","          epochs=50,\n","          callbacks=[metrics],\n","          batch_size=32)"],"execution_count":13,"outputs":[{"output_type":"stream","text":["Train on 25000 samples, validate on 25000 samples\n","Epoch 1/50\n","25000/25000 [==============================] - 541s 22ms/sample - loss: 0.6266 - accuracy: 0.6066 - val_loss: 0.6952 - val_accuracy: 0.5000\n","Epoch 2/50\n","25000/25000 [==============================] - 540s 22ms/sample - loss: 0.6975 - accuracy: 0.5018 - val_loss: 0.7064 - val_accuracy: 0.5000\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 3/50\n","25000/25000 [==============================] - 540s 22ms/sample - loss: 0.6951 - accuracy: 0.5050 - val_loss: 0.6940 - val_accuracy: 0.5000\n","Epoch 4/50\n","25000/25000 [==============================] - 541s 22ms/sample - loss: 0.6960 - accuracy: 0.4976 - val_loss: 0.7001 - val_accuracy: 0.5000\n","Epoch 5/50\n","25000/25000 [==============================] - 540s 22ms/sample - loss: 0.6952 - accuracy: 0.4970 - val_loss: 0.6935 - val_accuracy: 0.5000\n","Epoch 6/50\n","25000/25000 [==============================] - 542s 22ms/sample - loss: 0.6946 - accuracy: 0.5070 - val_loss: 0.6945 - val_accuracy: 0.5000\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 7/50\n"," 5792/25000 [=====>........................] - ETA: 3:52 - loss: 0.6953 - accuracy: 0.5031"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-13-052a9c842a75>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m           \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m           batch_size=32)\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_v1.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    783\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    784\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 785\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    786\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    787\u001b[0m   def evaluate(self,\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    664\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    665\u001b[0m         \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 666\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    667\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m   def evaluate(self,\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 386\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    387\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3630\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3631\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3632\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3633\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3634\u001b[0m     output_structure = nest.pack_sequence_as(\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"-4iyUZU_lYu7","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}