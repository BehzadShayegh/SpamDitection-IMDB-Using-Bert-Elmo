{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"NLP-CA#5-part2-Bert-FF-!Prep.ipynb","provenance":[{"file_id":"1Y7-s_TWyNeWnuNl0k44yykU-pURXuCBV","timestamp":1588957710140},{"file_id":"1VuZcbezljhvTdPrEdLVEbQFZ31zQWNXO","timestamp":1588877020091},{"file_id":"1JdL9q3iGekwNzxZeNJdlY092cNUCDRvZ","timestamp":1588867302500},{"file_id":"1XFJsydGgcCx_GspaoqQdJB_PVukTD8lI","timestamp":1588599657507}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"1f46efe16f174af38364ca1a2754bf83":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_611c98c0bcc0414685eba55f24b4a18c","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_ec0f1ff2a8904e7882731c0b72849cdb","IPY_MODEL_01bca6c5926b4f5388d495f12170db03"]}},"611c98c0bcc0414685eba55f24b4a18c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ec0f1ff2a8904e7882731c0b72849cdb":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_ba38334b65f1415496c0b7dc37be4d40","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":25000,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":25000,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d584ad51d9ca4245b2a118313838bb64"}},"01bca6c5926b4f5388d495f12170db03":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_004e6ace54f44d4ebc50587cbe991d6a","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 25000/25000 [00:00&lt;00:00, 65445.97it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c65128562e704dcfa9372ea0d45dcb41"}},"ba38334b65f1415496c0b7dc37be4d40":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"d584ad51d9ca4245b2a118313838bb64":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"004e6ace54f44d4ebc50587cbe991d6a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"c65128562e704dcfa9372ea0d45dcb41":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5701d166a16e4a0fabb8aaf6b684e3f6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_69a76cbe114a417b88817612554e83bc","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_6fe00db281fc4928a21c4b777fd9c1d9","IPY_MODEL_1ea99a351ad342f2be70ffa577c4e17b"]}},"69a76cbe114a417b88817612554e83bc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6fe00db281fc4928a21c4b777fd9c1d9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_2793263bec97468ab5069b0d60a7e4f3","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":25000,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":25000,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_2d3d7517ea244fc48b6563525e5968ed"}},"1ea99a351ad342f2be70ffa577c4e17b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_2903a4fd973f40e9b90b8cad2b8c8207","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 25000/25000 [00:00&lt;00:00, 308001.59it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_0f9763263b8b4c0f8fa934bfa9ddbf82"}},"2793263bec97468ab5069b0d60a7e4f3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"2d3d7517ea244fc48b6563525e5968ed":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2903a4fd973f40e9b90b8cad2b8c8207":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"0f9763263b8b4c0f8fa934bfa9ddbf82":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"dfa5e76f97d04601b9a873699f8ea1f2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_c87f287c59f34d32921cbe71f861971d","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_a57d0d8ae5944bc8b1cb308210cb5637","IPY_MODEL_22606b1e18e74e1db2badee5da6b7a1e"]}},"c87f287c59f34d32921cbe71f861971d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a57d0d8ae5944bc8b1cb308210cb5637":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_00a2c6bc4879453b901e2ce9b4c942a1","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":25000,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":25000,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f3ca0bea85594b64bc44ffc70cdc907b"}},"22606b1e18e74e1db2badee5da6b7a1e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_d8c274c3394b437595d77023b37e171e","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 25000/25000 [03:31&lt;00:00, 118.21it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_234f4fd174b44b128f2ffa1b92af11e0"}},"00a2c6bc4879453b901e2ce9b4c942a1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"f3ca0bea85594b64bc44ffc70cdc907b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d8c274c3394b437595d77023b37e171e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"234f4fd174b44b128f2ffa1b92af11e0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5754f53ecc4b40abbe23ef0fdf58fa58":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_329657989e794bce9acbcd5896ec1816","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_9e88e68aa5dc4d1a9ab6e215adcb8470","IPY_MODEL_b043e71717de4e80b3a562a8bc42df9c"]}},"329657989e794bce9acbcd5896ec1816":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9e88e68aa5dc4d1a9ab6e215adcb8470":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_62fb88f666964758b39069e15f38bf6b","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":25000,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":25000,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_8308e525b8fc46b58d0c75a222359256"}},"b043e71717de4e80b3a562a8bc42df9c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_ad90caccb30f46eea2d15d766eebf9b0","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 25000/25000 [01:58&lt;00:00, 211.82it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_3e64c1c943b645c488db6254a2ddc1b0"}},"62fb88f666964758b39069e15f38bf6b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"8308e525b8fc46b58d0c75a222359256":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ad90caccb30f46eea2d15d766eebf9b0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"3e64c1c943b645c488db6254a2ddc1b0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"id":"LlcEljcR2cCe","colab_type":"code","outputId":"56c3bfc8-dab7-4f79-95c8-71bb42e3610f","executionInfo":{"status":"ok","timestamp":1588961676086,"user_tz":-270,"elapsed":5865,"user":{"displayName":"Aref Afzali","photoUrl":"","userId":"04593065310074929856"}},"colab":{"base_uri":"https://localhost:8080/","height":341}},"source":["import tensorflow.compat.v1 as tf\n","!pip install transformers\n","tf.disable_eager_execution()\n","tf.test.gpu_device_name()"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (2.9.0)\n","Requirement already satisfied: tokenizers==0.7.0 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.86)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.4)\n","Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.4.5.1)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.9)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["'/device:GPU:0'"]},"metadata":{"tags":[]},"execution_count":1}]},{"cell_type":"code","metadata":{"id":"U2vMZhwyVEQI","colab_type":"code","colab":{}},"source":["import os\n","import urllib.request\n","import tarfile\n","\n","urllib.request.urlretrieve('http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz', 'dataset.gz')\n","with tarfile.open('dataset.gz', 'r:gz') as tar:\n","    tar.extractall()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"csvoNaOXQ5-b","colab_type":"code","colab":{}},"source":["path = \"aclImdb/{}/{}/\"\n","trainfils, testfils = [], []\n","for g,collection in {'train': trainfils, 'test': testfils}.items() :\n","  for i,p in enumerate(['neg','pos']) :\n","    folder = path.format(g,p)\n","    for name in os.listdir(folder) :\n","      record = {\n","          'name' : name,\n","          'text' : open(folder+name).read(),\n","          'label' : i\n","      }\n","      collection.append(record)\n","\n","import pandas as pd\n","\n","train_df = pd.DataFrame(trainfils)\n","test_df = pd.DataFrame(testfils)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vuqp9PBl_8zt","colab_type":"code","outputId":"59ecc893-c525-4b49-9916-504c2696f889","executionInfo":{"status":"ok","timestamp":1588961717188,"user_tz":-270,"elapsed":46422,"user":{"displayName":"Aref Afzali","photoUrl":"","userId":"04593065310074929856"}},"colab":{"base_uri":"https://localhost:8080/","height":189,"referenced_widgets":["1f46efe16f174af38364ca1a2754bf83","611c98c0bcc0414685eba55f24b4a18c","ec0f1ff2a8904e7882731c0b72849cdb","01bca6c5926b4f5388d495f12170db03","ba38334b65f1415496c0b7dc37be4d40","d584ad51d9ca4245b2a118313838bb64","004e6ace54f44d4ebc50587cbe991d6a","c65128562e704dcfa9372ea0d45dcb41","5701d166a16e4a0fabb8aaf6b684e3f6","69a76cbe114a417b88817612554e83bc","6fe00db281fc4928a21c4b777fd9c1d9","1ea99a351ad342f2be70ffa577c4e17b","2793263bec97468ab5069b0d60a7e4f3","2d3d7517ea244fc48b6563525e5968ed","2903a4fd973f40e9b90b8cad2b8c8207","0f9763263b8b4c0f8fa934bfa9ddbf82"]}},"source":["import pandas as pd\n","import numpy as np\n","import nltk\n","from nltk.tokenize import RegexpTokenizer\n","from nltk.corpus import stopwords\n","from tqdm.notebook import tqdm\n","import re\n","nltk.download('punkt')\n","nltk.download('stopwords')\n","tokenizer = RegexpTokenizer(r'\\w+')\n","tqdm.pandas()\n","\n","def cleanhtml(raw_html):\n","  cleanr = re.compile('<.*?>')\n","  cleantext = re.sub(cleanr, '', raw_html)\n","  return cleantext\n","\n","MAX_LEN = 128\n","def make_clean(s) :\n","  return s\n","\n","train_df['clean'] = train_df['text'].progress_apply(make_clean)\n","test_df['clean'] = test_df['text'].progress_apply(make_clean)"],"execution_count":4,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1f46efe16f174af38364ca1a2754bf83","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=25000.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5701d166a16e4a0fabb8aaf6b684e3f6","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=25000.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ifosW9VhVV3H","colab_type":"code","outputId":"c4008674-c5a9-4e35-b4bc-3b7efa57c83d","executionInfo":{"status":"ok","timestamp":1588961950022,"user_tz":-270,"elapsed":278838,"user":{"displayName":"Aref Afzali","photoUrl":"","userId":"04593065310074929856"}},"colab":{"base_uri":"https://localhost:8080/","height":117,"referenced_widgets":["dfa5e76f97d04601b9a873699f8ea1f2","c87f287c59f34d32921cbe71f861971d","a57d0d8ae5944bc8b1cb308210cb5637","22606b1e18e74e1db2badee5da6b7a1e","00a2c6bc4879453b901e2ce9b4c942a1","f3ca0bea85594b64bc44ffc70cdc907b","d8c274c3394b437595d77023b37e171e","234f4fd174b44b128f2ffa1b92af11e0","5754f53ecc4b40abbe23ef0fdf58fa58","329657989e794bce9acbcd5896ec1816","9e88e68aa5dc4d1a9ab6e215adcb8470","b043e71717de4e80b3a562a8bc42df9c","62fb88f666964758b39069e15f38bf6b","8308e525b8fc46b58d0c75a222359256","ad90caccb30f46eea2d15d766eebf9b0","3e64c1c943b645c488db6254a2ddc1b0"]}},"source":["from transformers import BertTokenizer\n","btokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n","\n","MAX_LEN = 128\n","for df in [train_df,test_df] :\n","    input_ids = []\n","    attention_masks = []\n","\n","    for sent in tqdm(df['clean']):\n","        encoded_dict = btokenizer.encode_plus(\n","                            sent,\n","                            add_special_tokens = True,\n","                            max_length = MAX_LEN,\n","                            pad_to_max_length = True,\n","                            return_attention_mask = True,\n","                            return_tensors = 'pt',\n","                      )\n","        input_ids.append(encoded_dict['input_ids'])\n","        attention_masks.append(encoded_dict['attention_mask'])\n","\n","    df['input_ids'] = input_ids\n","    df['attention_masks'] = attention_masks"],"execution_count":5,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"dfa5e76f97d04601b9a873699f8ea1f2","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=25000.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5754f53ecc4b40abbe23ef0fdf58fa58","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=25000.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1ydle9gnRwjr","colab_type":"code","outputId":"8b6489b7-36ea-4a97-bf45-4dad72770690","executionInfo":{"status":"ok","timestamp":1588961950026,"user_tz":-270,"elapsed":278444,"user":{"displayName":"Aref Afzali","photoUrl":"","userId":"04593065310074929856"}},"colab":{"base_uri":"https://localhost:8080/","height":204}},"source":["train_df.head()"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>name</th>\n","      <th>text</th>\n","      <th>label</th>\n","      <th>clean</th>\n","      <th>input_ids</th>\n","      <th>attention_masks</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>7735_1.txt</td>\n","      <td>The funny sound that you may hear when you eye...</td>\n","      <td>0</td>\n","      <td>The funny sound that you may hear when you eye...</td>\n","      <td>[[tensor(101), tensor(1996), tensor(6057), ten...</td>\n","      <td>[[tensor(1), tensor(1), tensor(1), tensor(1), ...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>10311_3.txt</td>\n","      <td>SPOILER ALERT In this generic and forgettable ...</td>\n","      <td>0</td>\n","      <td>SPOILER ALERT In this generic and forgettable ...</td>\n","      <td>[[tensor(101), tensor(27594), tensor(2121), te...</td>\n","      <td>[[tensor(1), tensor(1), tensor(1), tensor(1), ...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>6264_2.txt</td>\n","      <td>Nightmare Weekend is proof positive that some ...</td>\n","      <td>0</td>\n","      <td>Nightmare Weekend is proof positive that some ...</td>\n","      <td>[[tensor(101), tensor(10103), tensor(5353), te...</td>\n","      <td>[[tensor(1), tensor(1), tensor(1), tensor(1), ...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>11383_2.txt</td>\n","      <td>This is a truly awful \"B\" movie. It is witless...</td>\n","      <td>0</td>\n","      <td>This is a truly awful \"B\" movie. It is witless...</td>\n","      <td>[[tensor(101), tensor(2023), tensor(2003), ten...</td>\n","      <td>[[tensor(1), tensor(1), tensor(1), tensor(1), ...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>12149_4.txt</td>\n","      <td>Set in Providence, Rhode Island, Feeding the M...</td>\n","      <td>0</td>\n","      <td>Set in Providence, Rhode Island, Feeding the M...</td>\n","      <td>[[tensor(101), tensor(2275), tensor(1999), ten...</td>\n","      <td>[[tensor(1), tensor(1), tensor(1), tensor(1), ...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["          name  ...                                    attention_masks\n","0   7735_1.txt  ...  [[tensor(1), tensor(1), tensor(1), tensor(1), ...\n","1  10311_3.txt  ...  [[tensor(1), tensor(1), tensor(1), tensor(1), ...\n","2   6264_2.txt  ...  [[tensor(1), tensor(1), tensor(1), tensor(1), ...\n","3  11383_2.txt  ...  [[tensor(1), tensor(1), tensor(1), tensor(1), ...\n","4  12149_4.txt  ...  [[tensor(1), tensor(1), tensor(1), tensor(1), ...\n","\n","[5 rows x 6 columns]"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"hAPU3BMfxF3O","colab_type":"code","colab":{}},"source":["import tensorflow_hub as hub\n","from tensorflow.compat.v1.keras import backend as K\n","# https://github.com/strongio/keras-bert/blob/master/keras-bert.ipynb\n","class BertLayer(tf.keras.layers.Layer):\n","    def __init__(\n","        self,\n","        n_fine_tune_layers=10,\n","        pooling=\"first\",\n","        bert_path=\"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\",\n","        **kwargs,\n","    ):\n","        self.n_fine_tune_layers = n_fine_tune_layers\n","        self.trainable = True\n","        self.output_size = 768\n","        self.pooling = pooling\n","        self.bert_path = bert_path\n","        if self.pooling not in [\"first\", \"mean\"]:\n","            raise NameError(\n","                f\"Undefined pooling type (must be either first or mean, but is {self.pooling}\"\n","            )\n","\n","        super(BertLayer, self).__init__(**kwargs)\n","\n","    def build(self, input_shape):\n","        self.bert = hub.Module(\n","            self.bert_path, trainable=self.trainable, name=f\"{self.name}_module\"\n","        )\n","\n","        # Remove unused layers\n","        trainable_vars = self.bert.variables\n","        if self.pooling == \"first\":\n","            trainable_vars = [var for var in trainable_vars if not \"/cls/\" in var.name]\n","            trainable_layers = [\"pooler/dense\"]\n","\n","        elif self.pooling == \"mean\":\n","            trainable_vars = [\n","                var\n","                for var in trainable_vars\n","                if not \"/cls/\" in var.name and not \"/pooler/\" in var.name\n","            ]\n","            trainable_layers = []\n","        else:\n","            raise NameError(\n","                f\"Undefined pooling type (must be either first or mean, but is {self.pooling}\"\n","            )\n","\n","        # Select how many layers to fine tune\n","        for i in range(self.n_fine_tune_layers):\n","            trainable_layers.append(f\"encoder/layer_{str(11 - i)}\")\n","\n","        # Update trainable vars to contain only the specified layers\n","        trainable_vars = [\n","            var\n","            for var in trainable_vars\n","            if any([l in var.name for l in trainable_layers])\n","        ]\n","\n","        # Add to trainable weights\n","        for var in trainable_vars:\n","            self._trainable_weights.append(var)\n","\n","        for var in self.bert.variables:\n","            if var not in self._trainable_weights:\n","                self._non_trainable_weights.append(var)\n","\n","        super(BertLayer, self).build(input_shape)\n","\n","    def call(self, inputs):\n","        inputs = [K.cast(x, dtype=\"int32\") for x in inputs]\n","        input_ids, input_mask, segment_ids = inputs\n","        bert_inputs = dict(\n","            input_ids=input_ids, input_mask=input_mask, segment_ids=segment_ids\n","        )\n","        if self.pooling == \"first\":\n","            pooled = self.bert(inputs=bert_inputs, signature=\"tokens\", as_dict=True)[\n","                \"pooled_output\"\n","            ]\n","        elif self.pooling == \"mean\":\n","            result = self.bert(inputs=bert_inputs, signature=\"tokens\", as_dict=True)[\n","                \"sequence_output\"\n","            ]\n","\n","            mul_mask = lambda x, m: x * tf.expand_dims(m, axis=-1)\n","            masked_reduce_mean = lambda x, m: tf.reduce_sum(mul_mask(x, m), axis=1) / (\n","                    tf.reduce_sum(m, axis=1, keepdims=True) + 1e-10)\n","            input_mask = tf.cast(input_mask, tf.float32)\n","            pooled = masked_reduce_mean(result, input_mask)\n","        else:\n","            raise NameError(f\"Undefined pooling type (must be either first or mean, but is {self.pooling}\")\n","\n","        return pooled\n","\n","    def compute_output_shape(self, input_shape):\n","        return (input_shape[0], self.output_size)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XOT8afgW4CW-","colab_type":"code","outputId":"565affaf-97ac-4481-cd62-25c76edf9552","executionInfo":{"status":"ok","timestamp":1588961959698,"user_tz":-270,"elapsed":286917,"user":{"displayName":"Aref Afzali","photoUrl":"","userId":"04593065310074929856"}},"colab":{"base_uri":"https://localhost:8080/","height":595}},"source":["from tensorflow.compat.v1.keras import layers\n","from tensorflow.compat.v1.keras.models import Model\n","from tensorflow.compat.v1.keras.optimizers import Adam\n","\n","input_ids = layers.Input(shape=(MAX_LEN,), dtype=tf.int32, name=\"input_ids\")\n","input_mask = layers.Input(shape=(MAX_LEN,), dtype=tf.int32, name=\"input_mask\")\n","segment_ids = layers.Input(shape=(MAX_LEN,), dtype=tf.int32, name=\"segment_ids\")\n","bert_inputs = [input_ids, input_mask, segment_ids]\n","bert_output = BertLayer(n_fine_tune_layers=10, pooling=\"first\")(bert_inputs)\n","dense = layers.Dense(768, activation='relu')(bert_output)\n","pred = layers.Dense(1, activation='sigmoid')(dense)\n","model = Model(inputs=bert_inputs, outputs=pred)\n","model.compile(loss='binary_crossentropy', optimizer=Adam(lr=2e-4), metrics=['accuracy'])\n","model.summary()"],"execution_count":8,"outputs":[{"output_type":"stream","text":["INFO:absl:Using /tmp/tfhub_modules to cache modules.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:1666: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n","Instructions for updating:\n","If using Keras pass *_constraint arguments to layers.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:1666: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n","Instructions for updating:\n","If using Keras pass *_constraint arguments to layers.\n"],"name":"stderr"},{"output_type":"stream","text":["Model: \"model\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_ids (InputLayer)          [(None, 128)]        0                                            \n","__________________________________________________________________________________________________\n","input_mask (InputLayer)         [(None, 128)]        0                                            \n","__________________________________________________________________________________________________\n","segment_ids (InputLayer)        [(None, 128)]        0                                            \n","__________________________________________________________________________________________________\n","bert_layer (BertLayer)          (None, 768)          110104890   input_ids[0][0]                  \n","                                                                 input_mask[0][0]                 \n","                                                                 segment_ids[0][0]                \n","__________________________________________________________________________________________________\n","dense (Dense)                   (None, 768)          590592      bert_layer[0][0]                 \n","__________________________________________________________________________________________________\n","dense_1 (Dense)                 (None, 1)            769         dense[0][0]                      \n","==================================================================================================\n","Total params: 110,696,251\n","Trainable params: 72,060,673\n","Non-trainable params: 38,635,578\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"otnALpexNEO-","colab_type":"code","colab":{}},"source":["from tensorflow.compat.v1 import keras\n","\n","session = keras.backend.get_session()\n","init = tf.global_variables_initializer()\n","session.run(init)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"aF1FxPD5WeeO","colab_type":"code","colab":{}},"source":["import numpy as np\n","import sklearn.metrics as sklm\n","from tensorflow.compat.v1 import keras\n","\n","class Metrics(keras.callbacks.Callback):\n","    def __init__(self, val_data, batch_size = 32) :\n","        super().__init__()\n","        self.validation_data = val_data\n","        self.batch_size = batch_size\n","\n","    def on_train_begin(self, logs={}):\n","        self.loss = []\n","        self.precision = []\n","        self.recall = []\n","        self.f1s = []\n","        self.accuracy = []\n","        self.auc = []\n","\n","    def on_epoch_end(self, epoch, logs={}):\n","        score = np.asarray(self.model.predict(self.validation_data[0]))\n","        predict = np.squeeze(score.round()).reshape(-1)\n","        targ = self.validation_data[1]\n","        self.loss.append(logs['val_loss'])\n","        self.auc.append(sklm.roc_auc_score(targ, score))\n","        self.precision.append(sklm.precision_score(targ, predict))\n","        self.recall.append(sklm.recall_score(targ, predict))\n","        self.f1s.append(sklm.f1_score(targ, predict))\n","        self.accuracy.append(sklm.accuracy_score(targ, predict))\n","\n","        pd.DataFrame({\n","            'loss': self.loss,\n","            'precision': self.precision,\n","            'recall': self.recall,\n","            'f1s': self.f1s,\n","            'accuracy': self.accuracy,\n","            'auc': self.auc\n","        }).to_csv('recors.csv')\n","\n","        return"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"fO1Z03SOlc5D","colab_type":"code","colab":{}},"source":["import numpy as np\n","\n","# Create datasets (Only take up to MAX_LEN words)\n","train_ids = train_df['input_ids'].tolist()\n","train_ids = [t.tolist()[0:MAX_LEN] for t in train_ids]\n","train_ids = np.array(train_ids, dtype=int)[:, np.newaxis].reshape(train_df.shape[0],-1)\n","train_masks = train_df['attention_masks'].tolist()\n","train_masks = [t.tolist()[0:MAX_LEN] for t in train_masks]\n","train_masks = np.array(train_masks, dtype=int)[:, np.newaxis].reshape(train_df.shape[0],-1)\n","train_label = train_df['label'].tolist()\n","\n","test_ids = test_df['input_ids'].tolist()\n","test_ids = [t.tolist()[0:MAX_LEN] for t in test_ids]\n","test_ids = np.array(test_ids, dtype=int)[:, np.newaxis].reshape(test_df.shape[0],-1)\n","test_masks = test_df['attention_masks'].tolist()\n","test_masks = [t.tolist()[0:MAX_LEN] for t in test_masks]\n","test_masks = np.array(test_masks, dtype=int)[:, np.newaxis].reshape(test_df.shape[0],-1)\n","test_label = test_df['label'].tolist()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6MGKzKb7mHFE","colab_type":"code","colab":{}},"source":["# tf.compat.v1.experimental.output_all_intermediates(True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"lO8xmZ4R4CUc","colab_type":"code","outputId":"b5c4e950-fa9c-4081-d9d7-e64f45ecdfce","executionInfo":{"status":"error","timestamp":1588964761706,"user_tz":-270,"elapsed":3086833,"user":{"displayName":"Aref Afzali","photoUrl":"","userId":"04593065310074929856"}},"colab":{"base_uri":"https://localhost:8080/","height":720}},"source":["  # def variable_created_in_scope(self, v):\n","  #   if not hasattr(v, '_distribute_strategy'):\n","  #     v._distribute_strategy = None\n","  #   return v._distribute_strategy is None  # pylint: disable=protected-access\n","#==============================================================================================\n","metrics = Metrics(([test_ids, test_masks, np.zeros(test_ids.shape)], test_label))\n","\n","model.fit([train_ids, train_masks, np.zeros(train_ids.shape)], \n","          train_label,\n","          validation_data=([test_ids, test_masks, np.zeros(test_ids.shape)], test_label),\n","          epochs=50,\n","          callbacks=[metrics],\n","          batch_size=32)"],"execution_count":13,"outputs":[{"output_type":"stream","text":["Train on 25000 samples, validate on 25000 samples\n","Epoch 1/50\n","25000/25000 [==============================] - 541s 22ms/sample - loss: 0.7004 - accuracy: 0.5041 - val_loss: 0.6946 - val_accuracy: 0.5000\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 2/50\n","25000/25000 [==============================] - 540s 22ms/sample - loss: 0.6964 - accuracy: 0.4974 - val_loss: 0.6932 - val_accuracy: 0.5000\n","Epoch 3/50\n","25000/25000 [==============================] - 540s 22ms/sample - loss: 0.6957 - accuracy: 0.5041 - val_loss: 0.6931 - val_accuracy: 0.4999\n","Epoch 4/50\n","25000/25000 [==============================] - 539s 22ms/sample - loss: 0.6944 - accuracy: 0.5029 - val_loss: 0.6953 - val_accuracy: 0.5000\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 5/50\n","25000/25000 [==============================] - 539s 22ms/sample - loss: 0.6957 - accuracy: 0.5018 - val_loss: 0.6937 - val_accuracy: 0.5000\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 6/50\n"," 7200/25000 [=======>......................] - ETA: 3:34 - loss: 0.6952 - accuracy: 0.5014"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-13-052a9c842a75>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m           \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m           batch_size=32)\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_v1.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    783\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    784\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 785\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    786\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    787\u001b[0m   def evaluate(self,\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    664\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    665\u001b[0m         \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 666\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    667\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m   def evaluate(self,\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 386\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    387\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3630\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3631\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3632\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3633\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3634\u001b[0m     output_structure = nest.pack_sequence_as(\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"-4iyUZU_lYu7","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}