{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"NLP-CA#5-part1-Bert-FF-!Prep.ipynb","provenance":[{"file_id":"1Y7-s_TWyNeWnuNl0k44yykU-pURXuCBV","timestamp":1588956831054},{"file_id":"1VuZcbezljhvTdPrEdLVEbQFZ31zQWNXO","timestamp":1588877020091},{"file_id":"1JdL9q3iGekwNzxZeNJdlY092cNUCDRvZ","timestamp":1588867302500},{"file_id":"1XFJsydGgcCx_GspaoqQdJB_PVukTD8lI","timestamp":1588599657507}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"5f5b3eeaaf0047188dc76d4b5d494ce8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_70f5ca1e0fd14ca99ba87a3aa7c122c0","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_157e65eba8af49f4be62f28fe9522ec4","IPY_MODEL_5023132242524d39b0eac5048d84a2e7"]}},"70f5ca1e0fd14ca99ba87a3aa7c122c0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"157e65eba8af49f4be62f28fe9522ec4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_fc44e0d74d9b4ee09ccff9fa3b37bd3c","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":5572,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":5572,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_6b8456dd49554bc580800baef83e6df5"}},"5023132242524d39b0eac5048d84a2e7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_f262b0ce885747a49a2a736ac22650b6","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 5572/5572 [00:00&lt;00:00, 20691.85it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f6d4e41cefac4644bc4e82e7a708793d"}},"fc44e0d74d9b4ee09ccff9fa3b37bd3c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"6b8456dd49554bc580800baef83e6df5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f262b0ce885747a49a2a736ac22650b6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"f6d4e41cefac4644bc4e82e7a708793d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3656d6ba7f4c4eb89d4f1838d2d50e66":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_2bcdad6569c54bff833057cc8f13f16f","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_f6220e94cafc470c8e26b3a6c07fd568","IPY_MODEL_5eefd7588a534d228f0b98643b4e0fa7"]}},"2bcdad6569c54bff833057cc8f13f16f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f6220e94cafc470c8e26b3a6c07fd568":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_c943daad5dd64305be11a8f64b8d1f19","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":5572,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":5572,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_5e4f54b4c5614bdba1919cf9e5d34990"}},"5eefd7588a534d228f0b98643b4e0fa7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_6478abfe8e3842f28a836eb1061c2542","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 5572/5572 [00:07&lt;00:00, 774.04it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_79827170623843b7b53ea863fe07c1d5"}},"c943daad5dd64305be11a8f64b8d1f19":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"5e4f54b4c5614bdba1919cf9e5d34990":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6478abfe8e3842f28a836eb1061c2542":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"79827170623843b7b53ea863fe07c1d5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"id":"LlcEljcR2cCe","colab_type":"code","outputId":"6a6a1799-d859-46d9-86b4-fb0e042b9729","executionInfo":{"status":"ok","timestamp":1588957073192,"user_tz":-270,"elapsed":6593,"user":{"displayName":"Discrete Mathematics University of Tehran","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgZI8iY1tb8a-0NzY8jzzQD3v30wOpRaflP8d28=s64","userId":"11276251709456081481"}},"colab":{"base_uri":"https://localhost:8080/","height":341}},"source":["import tensorflow.compat.v1 as tf\n","!pip install transformers\n","tf.disable_eager_execution()\n","tf.test.gpu_device_name()"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (2.9.0)\n","Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n","Requirement already satisfied: tokenizers==0.7.0 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.4)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.86)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.9)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.4.5.1)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["'/device:GPU:0'"]},"metadata":{"tags":[]},"execution_count":1}]},{"cell_type":"code","metadata":{"id":"U2vMZhwyVEQI","colab_type":"code","colab":{}},"source":["# from google.colab import files\n","# files.upload()\n","# !pip install -q kaggle\n","# !mkdir -p ~/.kaggle\n","# !cp kaggle.json ~/.kaggle/\n","# !kaggle datasets download -d uciml/sms-spam-collection-dataset\n","# !unzip sms-spam-collection-dataset.zip"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vuqp9PBl_8zt","colab_type":"code","outputId":"dd7427d3-b8b2-4c40-c456-b88b6552bbc7","executionInfo":{"status":"ok","timestamp":1588957073610,"user_tz":-270,"elapsed":6948,"user":{"displayName":"Discrete Mathematics University of Tehran","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgZI8iY1tb8a-0NzY8jzzQD3v30wOpRaflP8d28=s64","userId":"11276251709456081481"}},"colab":{"base_uri":"https://localhost:8080/","height":139,"referenced_widgets":["5f5b3eeaaf0047188dc76d4b5d494ce8","70f5ca1e0fd14ca99ba87a3aa7c122c0","157e65eba8af49f4be62f28fe9522ec4","5023132242524d39b0eac5048d84a2e7","fc44e0d74d9b4ee09ccff9fa3b37bd3c","6b8456dd49554bc580800baef83e6df5","f262b0ce885747a49a2a736ac22650b6","f6d4e41cefac4644bc4e82e7a708793d"]}},"source":["import pandas as pd\n","import numpy as np\n","import nltk\n","from nltk.tokenize import RegexpTokenizer\n","from nltk.corpus import stopwords\n","from tqdm.notebook import tqdm\n","nltk.download('punkt')\n","nltk.download('stopwords')\n","tokenizer = RegexpTokenizer(r'\\w+')\n","tqdm.pandas()\n","\n","MAX_LEN = 128\n","def make_clean(s) :\n","  return s\n","\n","df = pd.read_csv('spam.csv', encoding = \"ISO-8859-1\")\n","df['clean'] = df['v2'].progress_apply(make_clean)\n","df['label'] = (df['v1']=='ham').astype(int)"],"execution_count":3,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5f5b3eeaaf0047188dc76d4b5d494ce8","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=5572.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ifosW9VhVV3H","colab_type":"code","outputId":"69568b5e-431e-43b7-ebe9-bb36ee84b90f","executionInfo":{"status":"ok","timestamp":1588957077950,"user_tz":-270,"elapsed":11235,"user":{"displayName":"Discrete Mathematics University of Tehran","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgZI8iY1tb8a-0NzY8jzzQD3v30wOpRaflP8d28=s64","userId":"11276251709456081481"}},"colab":{"base_uri":"https://localhost:8080/","height":67,"referenced_widgets":["3656d6ba7f4c4eb89d4f1838d2d50e66","2bcdad6569c54bff833057cc8f13f16f","f6220e94cafc470c8e26b3a6c07fd568","5eefd7588a534d228f0b98643b4e0fa7","c943daad5dd64305be11a8f64b8d1f19","5e4f54b4c5614bdba1919cf9e5d34990","6478abfe8e3842f28a836eb1061c2542","79827170623843b7b53ea863fe07c1d5"]}},"source":["from transformers import BertTokenizer\n","btokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n","\n","MAX_LEN = 128\n","input_ids = []\n","attention_masks = []\n","\n","for sent in tqdm(df['clean']):\n","    encoded_dict = btokenizer.encode_plus(\n","                        sent,\n","                        add_special_tokens = True,\n","                        max_length = MAX_LEN,\n","                        pad_to_max_length = True,\n","                        return_attention_mask = True,\n","                        return_tensors = 'pt',\n","                   )\n","    input_ids.append(encoded_dict['input_ids'])\n","    attention_masks.append(encoded_dict['attention_mask'])\n","\n","df['input_ids'] = input_ids\n","df['attention_masks'] = attention_masks"],"execution_count":4,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3656d6ba7f4c4eb89d4f1838d2d50e66","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=5572.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1ydle9gnRwjr","colab_type":"code","outputId":"2a079098-5e33-44ca-b7e6-76ddd2957ae0","executionInfo":{"status":"ok","timestamp":1588957077952,"user_tz":-270,"elapsed":11192,"user":{"displayName":"Discrete Mathematics University of Tehran","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgZI8iY1tb8a-0NzY8jzzQD3v30wOpRaflP8d28=s64","userId":"11276251709456081481"}},"colab":{"base_uri":"https://localhost:8080/","height":306}},"source":["random_index = np.zeros(df.shape[0]).astype(bool)\n","random_index[np.random.choice(df.shape[0], int(0.2*df.shape[0]))] = True\n","train_df, test_df = df[~random_index], df[random_index]\n","train_df.head()"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>v1</th>\n","      <th>v2</th>\n","      <th>Unnamed: 2</th>\n","      <th>Unnamed: 3</th>\n","      <th>Unnamed: 4</th>\n","      <th>clean</th>\n","      <th>label</th>\n","      <th>input_ids</th>\n","      <th>attention_masks</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>ham</td>\n","      <td>Go until jurong point, crazy.. Available only ...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Go until jurong point, crazy.. Available only ...</td>\n","      <td>1</td>\n","      <td>[[tensor(101), tensor(2175), tensor(2127), ten...</td>\n","      <td>[[tensor(1), tensor(1), tensor(1), tensor(1), ...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>spam</td>\n","      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n","      <td>0</td>\n","      <td>[[tensor(101), tensor(2489), tensor(4443), ten...</td>\n","      <td>[[tensor(1), tensor(1), tensor(1), tensor(1), ...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>ham</td>\n","      <td>Nah I don't think he goes to usf, he lives aro...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Nah I don't think he goes to usf, he lives aro...</td>\n","      <td>1</td>\n","      <td>[[tensor(101), tensor(20976), tensor(1045), te...</td>\n","      <td>[[tensor(1), tensor(1), tensor(1), tensor(1), ...</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>spam</td>\n","      <td>FreeMsg Hey there darling it's been 3 week's n...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>FreeMsg Hey there darling it's been 3 week's n...</td>\n","      <td>0</td>\n","      <td>[[tensor(101), tensor(2489), tensor(5244), ten...</td>\n","      <td>[[tensor(1), tensor(1), tensor(1), tensor(1), ...</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>ham</td>\n","      <td>As per your request 'Melle Melle (Oru Minnamin...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>As per your request 'Melle Melle (Oru Minnamin...</td>\n","      <td>1</td>\n","      <td>[[tensor(101), tensor(2004), tensor(2566), ten...</td>\n","      <td>[[tensor(1), tensor(1), tensor(1), tensor(1), ...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     v1  ...                                    attention_masks\n","0   ham  ...  [[tensor(1), tensor(1), tensor(1), tensor(1), ...\n","2  spam  ...  [[tensor(1), tensor(1), tensor(1), tensor(1), ...\n","4   ham  ...  [[tensor(1), tensor(1), tensor(1), tensor(1), ...\n","5  spam  ...  [[tensor(1), tensor(1), tensor(1), tensor(1), ...\n","7   ham  ...  [[tensor(1), tensor(1), tensor(1), tensor(1), ...\n","\n","[5 rows x 9 columns]"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"hAPU3BMfxF3O","colab_type":"code","colab":{}},"source":["import tensorflow_hub as hub\n","from tensorflow.compat.v1.keras import backend as K\n","# https://github.com/strongio/keras-bert/blob/master/keras-bert.ipynb\n","class BertLayer(tf.keras.layers.Layer):\n","    def __init__(\n","        self,\n","        n_fine_tune_layers=10,\n","        pooling=\"first\",\n","        bert_path=\"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\",\n","        **kwargs,\n","    ):\n","        self.n_fine_tune_layers = n_fine_tune_layers\n","        self.trainable = True\n","        self.output_size = 768\n","        self.pooling = pooling\n","        self.bert_path = bert_path\n","        if self.pooling not in [\"first\", \"mean\"]:\n","            raise NameError(\n","                f\"Undefined pooling type (must be either first or mean, but is {self.pooling}\"\n","            )\n","\n","        super(BertLayer, self).__init__(**kwargs)\n","\n","    def build(self, input_shape):\n","        self.bert = hub.Module(\n","            self.bert_path, trainable=self.trainable, name=f\"{self.name}_module\"\n","        )\n","\n","        # Remove unused layers\n","        trainable_vars = self.bert.variables\n","        if self.pooling == \"first\":\n","            trainable_vars = [var for var in trainable_vars if not \"/cls/\" in var.name]\n","            trainable_layers = [\"pooler/dense\"]\n","\n","        elif self.pooling == \"mean\":\n","            trainable_vars = [\n","                var\n","                for var in trainable_vars\n","                if not \"/cls/\" in var.name and not \"/pooler/\" in var.name\n","            ]\n","            trainable_layers = []\n","        else:\n","            raise NameError(\n","                f\"Undefined pooling type (must be either first or mean, but is {self.pooling}\"\n","            )\n","\n","        # Select how many layers to fine tune\n","        for i in range(self.n_fine_tune_layers):\n","            trainable_layers.append(f\"encoder/layer_{str(11 - i)}\")\n","\n","        # Update trainable vars to contain only the specified layers\n","        trainable_vars = [\n","            var\n","            for var in trainable_vars\n","            if any([l in var.name for l in trainable_layers])\n","        ]\n","\n","        # Add to trainable weights\n","        for var in trainable_vars:\n","            self._trainable_weights.append(var)\n","\n","        for var in self.bert.variables:\n","            if var not in self._trainable_weights:\n","                self._non_trainable_weights.append(var)\n","\n","        super(BertLayer, self).build(input_shape)\n","\n","    def call(self, inputs):\n","        inputs = [K.cast(x, dtype=\"int32\") for x in inputs]\n","        input_ids, input_mask, segment_ids = inputs\n","        bert_inputs = dict(\n","            input_ids=input_ids, input_mask=input_mask, segment_ids=segment_ids\n","        )\n","        if self.pooling == \"first\":\n","            pooled = self.bert(inputs=bert_inputs, signature=\"tokens\", as_dict=True)[\n","                \"pooled_output\"\n","            ]\n","        elif self.pooling == \"mean\":\n","            result = self.bert(inputs=bert_inputs, signature=\"tokens\", as_dict=True)[\n","                \"sequence_output\"\n","            ]\n","\n","            mul_mask = lambda x, m: x * tf.expand_dims(m, axis=-1)\n","            masked_reduce_mean = lambda x, m: tf.reduce_sum(mul_mask(x, m), axis=1) / (\n","                    tf.reduce_sum(m, axis=1, keepdims=True) + 1e-10)\n","            input_mask = tf.cast(input_mask, tf.float32)\n","            pooled = masked_reduce_mean(result, input_mask)\n","        else:\n","            raise NameError(f\"Undefined pooling type (must be either first or mean, but is {self.pooling}\")\n","\n","        return pooled\n","\n","    def compute_output_shape(self, input_shape):\n","        return (input_shape[0], self.output_size)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XOT8afgW4CW-","colab_type":"code","outputId":"336aa5a5-4c6f-4a82-8085-46b86cfd2628","executionInfo":{"status":"ok","timestamp":1588957091364,"user_tz":-270,"elapsed":24554,"user":{"displayName":"Discrete Mathematics University of Tehran","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgZI8iY1tb8a-0NzY8jzzQD3v30wOpRaflP8d28=s64","userId":"11276251709456081481"}},"colab":{"base_uri":"https://localhost:8080/","height":595}},"source":["from tensorflow.compat.v1.keras import layers\n","from tensorflow.compat.v1.keras.models import Model\n","from tensorflow.compat.v1.keras.optimizers import Adam\n","\n","input_ids = layers.Input(shape=(MAX_LEN,), dtype=tf.int32, name=\"input_ids\")\n","input_mask = layers.Input(shape=(MAX_LEN,), dtype=tf.int32, name=\"input_mask\")\n","segment_ids = layers.Input(shape=(MAX_LEN,), dtype=tf.int32, name=\"segment_ids\")\n","bert_inputs = [input_ids, input_mask, segment_ids]\n","bert_output = BertLayer(n_fine_tune_layers=10, pooling=\"first\")(bert_inputs)\n","dense = layers.Dense(768, activation='relu')(bert_output)\n","pred = layers.Dense(1, activation='sigmoid')(dense)\n","model = Model(inputs=bert_inputs, outputs=pred)\n","model.compile(loss='binary_crossentropy', optimizer=Adam(lr=2e-4), metrics=['accuracy'])\n","model.summary()"],"execution_count":7,"outputs":[{"output_type":"stream","text":["INFO:absl:Using /tmp/tfhub_modules to cache modules.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:1666: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n","Instructions for updating:\n","If using Keras pass *_constraint arguments to layers.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:1666: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n","Instructions for updating:\n","If using Keras pass *_constraint arguments to layers.\n"],"name":"stderr"},{"output_type":"stream","text":["Model: \"model\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_ids (InputLayer)          [(None, 128)]        0                                            \n","__________________________________________________________________________________________________\n","input_mask (InputLayer)         [(None, 128)]        0                                            \n","__________________________________________________________________________________________________\n","segment_ids (InputLayer)        [(None, 128)]        0                                            \n","__________________________________________________________________________________________________\n","bert_layer (BertLayer)          (None, 768)          110104890   input_ids[0][0]                  \n","                                                                 input_mask[0][0]                 \n","                                                                 segment_ids[0][0]                \n","__________________________________________________________________________________________________\n","dense (Dense)                   (None, 768)          590592      bert_layer[0][0]                 \n","__________________________________________________________________________________________________\n","dense_1 (Dense)                 (None, 1)            769         dense[0][0]                      \n","==================================================================================================\n","Total params: 110,696,251\n","Trainable params: 72,060,673\n","Non-trainable params: 38,635,578\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"otnALpexNEO-","colab_type":"code","colab":{}},"source":["from tensorflow.compat.v1 import keras\n","\n","session = keras.backend.get_session()\n","init = tf.global_variables_initializer()\n","session.run(init)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"aF1FxPD5WeeO","colab_type":"code","colab":{}},"source":["import numpy as np\n","import sklearn.metrics as sklm\n","from tensorflow.compat.v1 import keras\n","\n","class Metrics(keras.callbacks.Callback):\n","    def __init__(self, val_data, batch_size = 32) :\n","        super().__init__()\n","        self.validation_data = val_data\n","        self.batch_size = batch_size\n","\n","    def on_train_begin(self, logs={}):\n","        self.loss = []\n","        self.precision = []\n","        self.recall = []\n","        self.f1s = []\n","        self.accuracy = []\n","        self.auc = []\n","\n","    def on_epoch_end(self, epoch, logs={}):\n","        score = np.asarray(self.model.predict(self.validation_data[0]))\n","        predict = np.squeeze(score.round()).reshape(-1)\n","        targ = self.validation_data[1]\n","        self.loss.append(logs['val_loss'])\n","        self.auc.append(sklm.roc_auc_score(targ, score))\n","        self.precision.append(sklm.precision_score(targ, predict))\n","        self.recall.append(sklm.recall_score(targ, predict))\n","        self.f1s.append(sklm.f1_score(targ, predict))\n","        self.accuracy.append(sklm.accuracy_score(targ, predict))\n","\n","        pd.DataFrame({\n","            'loss': self.loss,\n","            'precision': self.precision,\n","            'recall': self.recall,\n","            'f1s': self.f1s,\n","            'accuracy': self.accuracy,\n","            'auc': self.auc\n","        }).to_csv('recors.csv')\n","\n","        return"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"fO1Z03SOlc5D","colab_type":"code","colab":{}},"source":["import numpy as np\n","\n","# Create datasets (Only take up to MAX_LEN words)\n","train_ids = train_df['input_ids'].tolist()\n","train_ids = [t.tolist()[0:MAX_LEN] for t in train_ids]\n","train_ids = np.array(train_ids, dtype=int)[:, np.newaxis].reshape(train_df.shape[0],-1)\n","train_masks = train_df['attention_masks'].tolist()\n","train_masks = [t.tolist()[0:MAX_LEN] for t in train_masks]\n","train_masks = np.array(train_masks, dtype=int)[:, np.newaxis].reshape(train_df.shape[0],-1)\n","train_label = train_df['label'].tolist()\n","\n","test_ids = test_df['input_ids'].tolist()\n","test_ids = [t.tolist()[0:MAX_LEN] for t in test_ids]\n","test_ids = np.array(test_ids, dtype=int)[:, np.newaxis].reshape(test_df.shape[0],-1)\n","test_masks = test_df['attention_masks'].tolist()\n","test_masks = [t.tolist()[0:MAX_LEN] for t in test_masks]\n","test_masks = np.array(test_masks, dtype=int)[:, np.newaxis].reshape(test_df.shape[0],-1)\n","test_label = test_df['label'].tolist()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6MGKzKb7mHFE","colab_type":"code","colab":{}},"source":["# tf.compat.v1.experimental.output_all_intermediates(True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"lO8xmZ4R4CUc","colab_type":"code","outputId":"c6f80c59-a587-4f12-871f-e20afd876990","executionInfo":{"status":"error","timestamp":1588960203372,"user_tz":-270,"elapsed":3136451,"user":{"displayName":"Discrete Mathematics University of Tehran","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgZI8iY1tb8a-0NzY8jzzQD3v30wOpRaflP8d28=s64","userId":"11276251709456081481"}},"colab":{"base_uri":"https://localhost:8080/","height":916}},"source":["  # def variable_created_in_scope(self, v):\n","  #   if not hasattr(v, '_distribute_strategy'):\n","  #     v._distribute_strategy = None\n","  #   return v._distribute_strategy is None  # pylint: disable=protected-access\n","#==============================================================================================\n","metrics = Metrics(([test_ids, test_masks, np.zeros(test_ids.shape)], test_label))\n","\n","model.fit([train_ids, train_masks, np.zeros(train_ids.shape)], \n","          train_label,\n","          validation_data=([test_ids, test_masks, np.zeros(test_ids.shape)], test_label),\n","          epochs=50,\n","          callbacks=[metrics],\n","          batch_size=32)"],"execution_count":12,"outputs":[{"output_type":"stream","text":["Train on 4557 samples, validate on 1015 samples\n","Epoch 1/50\n","4557/4557 [==============================] - 213s 47ms/sample - loss: 0.1467 - accuracy: 0.9642 - val_loss: 0.1172 - val_accuracy: 0.9773\n","Epoch 2/50\n","4557/4557 [==============================] - 210s 46ms/sample - loss: 0.1570 - accuracy: 0.9511 - val_loss: 0.1587 - val_accuracy: 0.9409\n","Epoch 3/50\n","4557/4557 [==============================] - 210s 46ms/sample - loss: 0.1147 - accuracy: 0.9704 - val_loss: 0.1426 - val_accuracy: 0.9567\n","Epoch 4/50\n","4557/4557 [==============================] - 210s 46ms/sample - loss: 0.3649 - accuracy: 0.8868 - val_loss: 0.4116 - val_accuracy: 0.8571\n","Epoch 5/50\n","4557/4557 [==============================] - 210s 46ms/sample - loss: 0.4078 - accuracy: 0.8679 - val_loss: 0.4102 - val_accuracy: 0.8571\n","Epoch 6/50\n","4557/4557 [==============================] - 210s 46ms/sample - loss: 0.4129 - accuracy: 0.8679 - val_loss: 0.4146 - val_accuracy: 0.8571\n","Epoch 7/50\n","4557/4557 [==============================] - 210s 46ms/sample - loss: 0.4039 - accuracy: 0.8679 - val_loss: 0.4628 - val_accuracy: 0.8571\n","Epoch 8/50\n","4557/4557 [==============================] - 210s 46ms/sample - loss: 0.4173 - accuracy: 0.8679 - val_loss: 0.4145 - val_accuracy: 0.8571\n","Epoch 9/50\n","4557/4557 [==============================] - 210s 46ms/sample - loss: 0.3980 - accuracy: 0.8679 - val_loss: 0.4401 - val_accuracy: 0.8571\n","Epoch 10/50\n","4557/4557 [==============================] - 210s 46ms/sample - loss: 0.4022 - accuracy: 0.8679 - val_loss: 0.4112 - val_accuracy: 0.8571\n","Epoch 11/50\n","4557/4557 [==============================] - 210s 46ms/sample - loss: 0.3967 - accuracy: 0.8679 - val_loss: 0.4298 - val_accuracy: 0.8571\n","Epoch 12/50\n","4557/4557 [==============================] - 210s 46ms/sample - loss: 0.4012 - accuracy: 0.8679 - val_loss: 0.4215 - val_accuracy: 0.8571\n","Epoch 13/50\n","4557/4557 [==============================] - 209s 46ms/sample - loss: 0.3980 - accuracy: 0.8679 - val_loss: 0.4144 - val_accuracy: 0.8571\n","Epoch 14/50\n","4557/4557 [==============================] - 210s 46ms/sample - loss: 0.4007 - accuracy: 0.8679 - val_loss: 0.4119 - val_accuracy: 0.8571\n","Epoch 15/50\n","3424/4557 [=====================>........] - ETA: 43s - loss: 0.3888 - accuracy: 0.8715"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-12-052a9c842a75>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m           \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m           batch_size=32)\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_v1.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    783\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    784\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 785\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    786\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    787\u001b[0m   def evaluate(self,\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    664\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    665\u001b[0m         \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 666\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    667\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m   def evaluate(self,\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 386\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    387\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3630\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3631\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3632\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3633\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3634\u001b[0m     output_structure = nest.pack_sequence_as(\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"-4iyUZU_lYu7","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}