{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"NLP-CA#5-part1-Bert-Special-!Prep.ipynb","provenance":[{"file_id":"1uTWuCObbL5wI6A3u5cn8Ufp96E8VIEah","timestamp":1588957266189},{"file_id":"1Y7-s_TWyNeWnuNl0k44yykU-pURXuCBV","timestamp":1588956831054},{"file_id":"1VuZcbezljhvTdPrEdLVEbQFZ31zQWNXO","timestamp":1588877020091},{"file_id":"1JdL9q3iGekwNzxZeNJdlY092cNUCDRvZ","timestamp":1588867302500},{"file_id":"1XFJsydGgcCx_GspaoqQdJB_PVukTD8lI","timestamp":1588599657507}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"e4fa6b64d3414f8a981d489ca0550952":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_682af6c052894fc099e1046af6d76bf3","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_a08a3293458a479aac150bb876c019a2","IPY_MODEL_6daf2ed9d73b4f81bf880045c5787b76"]}},"682af6c052894fc099e1046af6d76bf3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a08a3293458a479aac150bb876c019a2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_7aa9007d49294a6f8e9ce74a4909e27e","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":5572,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":5572,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_1042561476f4431a97300a474591e4f7"}},"6daf2ed9d73b4f81bf880045c5787b76":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_4144a3875a4e40f3b5ca81aa5fbcfb76","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 5572/5572 [00:00&lt;00:00, 24131.48it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_222dc650e3524cfe950e29eae7fc9f04"}},"7aa9007d49294a6f8e9ce74a4909e27e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"1042561476f4431a97300a474591e4f7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4144a3875a4e40f3b5ca81aa5fbcfb76":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"222dc650e3524cfe950e29eae7fc9f04":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0ea1c4a74f2b4056845161f71769d7ee":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_23d20534ed944fb09dd1751af1f13362","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_204801e6d4864bf5bad0725dde751a7c","IPY_MODEL_d4c79522c3a34a7983b81a757ea1e067"]}},"23d20534ed944fb09dd1751af1f13362":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"204801e6d4864bf5bad0725dde751a7c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_a69ac37ad9be43b4aecb69e1d3129578","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":5572,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":5572,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e3abbd95b6ec4e029f05d1ec4db34f72"}},"d4c79522c3a34a7983b81a757ea1e067":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_d56159621b0b4f33b0f3fc0497265b31","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 5572/5572 [00:05&lt;00:00, 1068.60it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_81bf632eb5f24f5287d1554d33191fb9"}},"a69ac37ad9be43b4aecb69e1d3129578":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"e3abbd95b6ec4e029f05d1ec4db34f72":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d56159621b0b4f33b0f3fc0497265b31":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"81bf632eb5f24f5287d1554d33191fb9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"id":"LlcEljcR2cCe","colab_type":"code","outputId":"88963877-d651-4285-a0e2-b8db4698ba4f","executionInfo":{"status":"ok","timestamp":1588957613241,"user_tz":-270,"elapsed":9692,"user":{"displayName":"Aref Afzali","photoUrl":"","userId":"04593065310074929856"}},"colab":{"base_uri":"https://localhost:8080/","height":341}},"source":["import tensorflow.compat.v1 as tf\n","!pip install transformers\n","tf.disable_eager_execution()\n","tf.test.gpu_device_name()"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (2.9.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.86)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: tokenizers==0.7.0 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7.0)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.9)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.4.5.1)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["'/device:GPU:0'"]},"metadata":{"tags":[]},"execution_count":1}]},{"cell_type":"code","metadata":{"id":"U2vMZhwyVEQI","colab_type":"code","colab":{}},"source":["# from google.colab import files\n","# files.upload()\n","# !pip install -q kaggle\n","# !mkdir -p ~/.kaggle\n","# !cp kaggle.json ~/.kaggle/\n","# !kaggle datasets download -d uciml/sms-spam-collection-dataset\n","# !unzip sms-spam-collection-dataset.zip"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vuqp9PBl_8zt","colab_type":"code","outputId":"7c0a0d7b-d013-4d57-80c2-1c6f1b759dc5","executionInfo":{"status":"ok","timestamp":1588957613247,"user_tz":-270,"elapsed":9669,"user":{"displayName":"Aref Afzali","photoUrl":"","userId":"04593065310074929856"}},"colab":{"base_uri":"https://localhost:8080/","height":139,"referenced_widgets":["e4fa6b64d3414f8a981d489ca0550952","682af6c052894fc099e1046af6d76bf3","a08a3293458a479aac150bb876c019a2","6daf2ed9d73b4f81bf880045c5787b76","7aa9007d49294a6f8e9ce74a4909e27e","1042561476f4431a97300a474591e4f7","4144a3875a4e40f3b5ca81aa5fbcfb76","222dc650e3524cfe950e29eae7fc9f04"]}},"source":["import pandas as pd\n","import numpy as np\n","import nltk\n","from nltk.tokenize import RegexpTokenizer\n","from nltk.corpus import stopwords\n","from tqdm.notebook import tqdm\n","nltk.download('punkt')\n","nltk.download('stopwords')\n","tokenizer = RegexpTokenizer(r'\\w+')\n","tqdm.pandas()\n","\n","MAX_LEN = 128\n","def make_clean(s) :\n","  return s\n","\n","df = pd.read_csv('spam.csv', encoding = \"ISO-8859-1\")\n","df['clean'] = df['v2'].progress_apply(make_clean)\n","df['label'] = (df['v1']=='ham').astype(int)"],"execution_count":3,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e4fa6b64d3414f8a981d489ca0550952","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=5572.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ifosW9VhVV3H","colab_type":"code","outputId":"8c7d97ff-54d3-4ddc-f163-054d673d3f85","executionInfo":{"status":"ok","timestamp":1588957615754,"user_tz":-270,"elapsed":12107,"user":{"displayName":"Aref Afzali","photoUrl":"","userId":"04593065310074929856"}},"colab":{"base_uri":"https://localhost:8080/","height":67,"referenced_widgets":["0ea1c4a74f2b4056845161f71769d7ee","23d20534ed944fb09dd1751af1f13362","204801e6d4864bf5bad0725dde751a7c","d4c79522c3a34a7983b81a757ea1e067","a69ac37ad9be43b4aecb69e1d3129578","e3abbd95b6ec4e029f05d1ec4db34f72","d56159621b0b4f33b0f3fc0497265b31","81bf632eb5f24f5287d1554d33191fb9"]}},"source":["from transformers import BertTokenizer\n","btokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n","\n","MAX_LEN = 128\n","input_ids = []\n","attention_masks = []\n","\n","for sent in tqdm(df['clean']):\n","    encoded_dict = btokenizer.encode_plus(\n","                        sent,\n","                        add_special_tokens = True,\n","                        max_length = MAX_LEN,\n","                        pad_to_max_length = True,\n","                        return_attention_mask = True,\n","                        return_tensors = 'pt',\n","                   )\n","    input_ids.append(encoded_dict['input_ids'])\n","    attention_masks.append(encoded_dict['attention_mask'])\n","\n","df['input_ids'] = input_ids\n","df['attention_masks'] = attention_masks"],"execution_count":4,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0ea1c4a74f2b4056845161f71769d7ee","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=5572.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1ydle9gnRwjr","colab_type":"code","outputId":"9f4c9367-db0d-4f0c-884e-defbc04cf620","executionInfo":{"status":"ok","timestamp":1588957616961,"user_tz":-270,"elapsed":12827,"user":{"displayName":"Aref Afzali","photoUrl":"","userId":"04593065310074929856"}},"colab":{"base_uri":"https://localhost:8080/","height":306}},"source":["random_index = np.zeros(df.shape[0]).astype(bool)\n","random_index[np.random.choice(df.shape[0], int(0.2*df.shape[0]))] = True\n","train_df, test_df = df[~random_index], df[random_index]\n","train_df.head()"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>v1</th>\n","      <th>v2</th>\n","      <th>Unnamed: 2</th>\n","      <th>Unnamed: 3</th>\n","      <th>Unnamed: 4</th>\n","      <th>clean</th>\n","      <th>label</th>\n","      <th>input_ids</th>\n","      <th>attention_masks</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>ham</td>\n","      <td>Go until jurong point, crazy.. Available only ...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Go until jurong point, crazy.. Available only ...</td>\n","      <td>1</td>\n","      <td>[[tensor(101), tensor(2175), tensor(2127), ten...</td>\n","      <td>[[tensor(1), tensor(1), tensor(1), tensor(1), ...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>ham</td>\n","      <td>U dun say so early hor... U c already then say...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>U dun say so early hor... U c already then say...</td>\n","      <td>1</td>\n","      <td>[[tensor(101), tensor(1057), tensor(24654), te...</td>\n","      <td>[[tensor(1), tensor(1), tensor(1), tensor(1), ...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>ham</td>\n","      <td>Nah I don't think he goes to usf, he lives aro...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Nah I don't think he goes to usf, he lives aro...</td>\n","      <td>1</td>\n","      <td>[[tensor(101), tensor(20976), tensor(1045), te...</td>\n","      <td>[[tensor(1), tensor(1), tensor(1), tensor(1), ...</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>spam</td>\n","      <td>FreeMsg Hey there darling it's been 3 week's n...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>FreeMsg Hey there darling it's been 3 week's n...</td>\n","      <td>0</td>\n","      <td>[[tensor(101), tensor(2489), tensor(5244), ten...</td>\n","      <td>[[tensor(1), tensor(1), tensor(1), tensor(1), ...</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>ham</td>\n","      <td>Even my brother is not like to speak with me. ...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Even my brother is not like to speak with me. ...</td>\n","      <td>1</td>\n","      <td>[[tensor(101), tensor(2130), tensor(2026), ten...</td>\n","      <td>[[tensor(1), tensor(1), tensor(1), tensor(1), ...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     v1  ...                                    attention_masks\n","0   ham  ...  [[tensor(1), tensor(1), tensor(1), tensor(1), ...\n","3   ham  ...  [[tensor(1), tensor(1), tensor(1), tensor(1), ...\n","4   ham  ...  [[tensor(1), tensor(1), tensor(1), tensor(1), ...\n","5  spam  ...  [[tensor(1), tensor(1), tensor(1), tensor(1), ...\n","6   ham  ...  [[tensor(1), tensor(1), tensor(1), tensor(1), ...\n","\n","[5 rows x 9 columns]"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"hAPU3BMfxF3O","colab_type":"code","colab":{}},"source":["import tensorflow_hub as hub\n","from tensorflow.compat.v1.keras import backend as K\n","# https://github.com/strongio/keras-bert/blob/master/keras-bert.ipynb\n","class BertLayer(tf.keras.layers.Layer):\n","    def __init__(\n","        self,\n","        n_fine_tune_layers=10,\n","        pooling=\"first\",\n","        bert_path=\"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\",\n","        **kwargs,\n","    ):\n","        self.n_fine_tune_layers = n_fine_tune_layers\n","        self.trainable = True\n","        self.output_size = 768\n","        self.pooling = pooling\n","        self.bert_path = bert_path\n","        if self.pooling not in [\"first\", \"mean\"]:\n","            raise NameError(\n","                f\"Undefined pooling type (must be either first or mean, but is {self.pooling}\"\n","            )\n","\n","        super(BertLayer, self).__init__(**kwargs)\n","\n","    def build(self, input_shape):\n","        self.bert = hub.Module(\n","            self.bert_path, trainable=self.trainable, name=f\"{self.name}_module\"\n","        )\n","\n","        # Remove unused layers\n","        trainable_vars = self.bert.variables\n","        if self.pooling == \"first\":\n","            trainable_vars = [var for var in trainable_vars if not \"/cls/\" in var.name]\n","            trainable_layers = [\"pooler/dense\"]\n","\n","        elif self.pooling == \"mean\":\n","            trainable_vars = [\n","                var\n","                for var in trainable_vars\n","                if not \"/cls/\" in var.name and not \"/pooler/\" in var.name\n","            ]\n","            trainable_layers = []\n","        else:\n","            raise NameError(\n","                f\"Undefined pooling type (must be either first or mean, but is {self.pooling}\"\n","            )\n","\n","        # Select how many layers to fine tune\n","        for i in range(self.n_fine_tune_layers):\n","            trainable_layers.append(f\"encoder/layer_{str(11 - i)}\")\n","\n","        # Update trainable vars to contain only the specified layers\n","        trainable_vars = [\n","            var\n","            for var in trainable_vars\n","            if any([l in var.name for l in trainable_layers])\n","        ]\n","\n","        # Add to trainable weights\n","        for var in trainable_vars:\n","            self._trainable_weights.append(var)\n","\n","        for var in self.bert.variables:\n","            if var not in self._trainable_weights:\n","                self._non_trainable_weights.append(var)\n","\n","        super(BertLayer, self).build(input_shape)\n","\n","    def call(self, inputs):\n","        inputs = [K.cast(x, dtype=\"int32\") for x in inputs]\n","        input_ids, input_mask, segment_ids = inputs\n","        bert_inputs = dict(\n","            input_ids=input_ids, input_mask=input_mask, segment_ids=segment_ids\n","        )\n","        if self.pooling == \"first\":\n","            pooled = self.bert(inputs=bert_inputs, signature=\"tokens\", as_dict=True)[\n","                \"pooled_output\"\n","            ]\n","        elif self.pooling == \"mean\":\n","            result = self.bert(inputs=bert_inputs, signature=\"tokens\", as_dict=True)[\n","                \"sequence_output\"\n","            ]\n","\n","            mul_mask = lambda x, m: x * tf.expand_dims(m, axis=-1)\n","            masked_reduce_mean = lambda x, m: tf.reduce_sum(mul_mask(x, m), axis=1) / (\n","                    tf.reduce_sum(m, axis=1, keepdims=True) + 1e-10)\n","            input_mask = tf.cast(input_mask, tf.float32)\n","            pooled = masked_reduce_mean(result, input_mask)\n","        else:\n","            raise NameError(f\"Undefined pooling type (must be either first or mean, but is {self.pooling}\")\n","\n","        return pooled\n","\n","    def compute_output_shape(self, input_shape):\n","        return (input_shape[0], self.output_size)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"YKhhyYaVPUOb","colab_type":"code","colab":{}},"source":["class NonMasking(tf.keras.layers.Layer):   \n","    def __init__(self, **kwargs):   \n","        self.supports_masking = True  \n","        super(NonMasking, self).__init__(**kwargs)   \n","  \n","    def build(self, input_shape):   \n","        input_shape = input_shape   \n","  \n","    def compute_mask(self, input, input_mask=None):   \n","        # do not pass the mask to the next layers   \n","        return None   \n","  \n","    def call(self, x, mask=None):   \n","        return x   \n","  \n","    def get_output_shape_for(self, input_shape):   \n","        return input_shape  "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XOT8afgW4CW-","colab_type":"code","outputId":"7f29428f-c853-4166-f8bd-c8af021e5bf0","executionInfo":{"status":"ok","timestamp":1588957626311,"user_tz":-270,"elapsed":20690,"user":{"displayName":"Aref Afzali","photoUrl":"","userId":"04593065310074929856"}},"colab":{"base_uri":"https://localhost:8080/","height":775}},"source":["from tensorflow.compat.v1.keras import layers\n","from tensorflow.compat.v1.keras.models import Model\n","from tensorflow.compat.v1.keras.optimizers import Adam\n","\n","input_ids = layers.Input(shape=(MAX_LEN,), dtype=tf.int32, name=\"input_ids\")\n","input_mask = layers.Input(shape=(MAX_LEN,), dtype=tf.int32, name=\"input_mask\")\n","segment_ids = layers.Input(shape=(MAX_LEN,), dtype=tf.int32, name=\"segment_ids\")\n","bert_inputs = [input_ids, input_mask, segment_ids]\n","bert_output = BertLayer(n_fine_tune_layers=10, pooling=\"first\")(bert_inputs)\n","densembd = layers.Dense(768, activation='relu')(bert_output)\n","nmsk = NonMasking()(densembd)\n","rshp = layers.Reshape((-1,768))(nmsk)\n","convolution = layers.Convolution1D(50, 3, padding='same', activation='relu')(rshp)\n","convolution = layers.GlobalMaxPooling1D()(convolution)\n","dense = layers.Dense(50, activation='relu')(convolution)\n","pred = layers.Dense(1, activation='sigmoid')(dense)\n","model = Model(inputs=bert_inputs, outputs=pred)\n","model.compile(loss='binary_crossentropy', optimizer=Adam(lr=2e-4), metrics=['accuracy'])\n","model.summary()"],"execution_count":8,"outputs":[{"output_type":"stream","text":["INFO:absl:Using /tmp/tfhub_modules to cache modules.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:1666: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n","Instructions for updating:\n","If using Keras pass *_constraint arguments to layers.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:1666: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n","Instructions for updating:\n","If using Keras pass *_constraint arguments to layers.\n"],"name":"stderr"},{"output_type":"stream","text":["Model: \"model\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_ids (InputLayer)          [(None, 128)]        0                                            \n","__________________________________________________________________________________________________\n","input_mask (InputLayer)         [(None, 128)]        0                                            \n","__________________________________________________________________________________________________\n","segment_ids (InputLayer)        [(None, 128)]        0                                            \n","__________________________________________________________________________________________________\n","bert_layer (BertLayer)          (None, 768)          110104890   input_ids[0][0]                  \n","                                                                 input_mask[0][0]                 \n","                                                                 segment_ids[0][0]                \n","__________________________________________________________________________________________________\n","dense (Dense)                   (None, 768)          590592      bert_layer[0][0]                 \n","__________________________________________________________________________________________________\n","non_masking (NonMasking)        (None, 768)          0           dense[0][0]                      \n","__________________________________________________________________________________________________\n","reshape (Reshape)               (None, None, 768)    0           non_masking[0][0]                \n","__________________________________________________________________________________________________\n","conv1d (Conv1D)                 (None, None, 50)     115250      reshape[0][0]                    \n","__________________________________________________________________________________________________\n","global_max_pooling1d (GlobalMax (None, 50)           0           conv1d[0][0]                     \n","__________________________________________________________________________________________________\n","dense_1 (Dense)                 (None, 50)           2550        global_max_pooling1d[0][0]       \n","__________________________________________________________________________________________________\n","dense_2 (Dense)                 (None, 1)            51          dense_1[0][0]                    \n","==================================================================================================\n","Total params: 110,813,333\n","Trainable params: 72,177,755\n","Non-trainable params: 38,635,578\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"otnALpexNEO-","colab_type":"code","colab":{}},"source":["from tensorflow.compat.v1 import keras\n","\n","session = keras.backend.get_session()\n","init = tf.global_variables_initializer()\n","session.run(init)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"aF1FxPD5WeeO","colab_type":"code","colab":{}},"source":["import numpy as np\n","import sklearn.metrics as sklm\n","from tensorflow.compat.v1 import keras\n","\n","class Metrics(keras.callbacks.Callback):\n","    def __init__(self, val_data, batch_size = 32) :\n","        super().__init__()\n","        self.validation_data = val_data\n","        self.batch_size = batch_size\n","\n","    def on_train_begin(self, logs={}):\n","        self.loss = []\n","        self.precision = []\n","        self.recall = []\n","        self.f1s = []\n","        self.accuracy = []\n","        self.auc = []\n","\n","    def on_epoch_end(self, epoch, logs={}):\n","        score = np.asarray(self.model.predict(self.validation_data[0]))\n","        predict = np.squeeze(score.round()).reshape(-1)\n","        targ = self.validation_data[1]\n","        self.loss.append(logs['val_loss'])\n","        self.auc.append(sklm.roc_auc_score(targ, score))\n","        self.precision.append(sklm.precision_score(targ, predict))\n","        self.recall.append(sklm.recall_score(targ, predict))\n","        self.f1s.append(sklm.f1_score(targ, predict))\n","        self.accuracy.append(sklm.accuracy_score(targ, predict))\n","\n","        pd.DataFrame({\n","            'loss': self.loss,\n","            'precision': self.precision,\n","            'recall': self.recall,\n","            'f1s': self.f1s,\n","            'accuracy': self.accuracy,\n","            'auc': self.auc\n","        }).to_csv('recors.csv')\n","\n","        return"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"fO1Z03SOlc5D","colab_type":"code","colab":{}},"source":["import numpy as np\n","\n","# Create datasets (Only take up to MAX_LEN words)\n","train_ids = train_df['input_ids'].tolist()\n","train_ids = [t.tolist()[0:MAX_LEN] for t in train_ids]\n","train_ids = np.array(train_ids, dtype=int)[:, np.newaxis].reshape(train_df.shape[0],-1)\n","train_masks = train_df['attention_masks'].tolist()\n","train_masks = [t.tolist()[0:MAX_LEN] for t in train_masks]\n","train_masks = np.array(train_masks, dtype=int)[:, np.newaxis].reshape(train_df.shape[0],-1)\n","train_label = train_df['label'].tolist()\n","\n","test_ids = test_df['input_ids'].tolist()\n","test_ids = [t.tolist()[0:MAX_LEN] for t in test_ids]\n","test_ids = np.array(test_ids, dtype=int)[:, np.newaxis].reshape(test_df.shape[0],-1)\n","test_masks = test_df['attention_masks'].tolist()\n","test_masks = [t.tolist()[0:MAX_LEN] for t in test_masks]\n","test_masks = np.array(test_masks, dtype=int)[:, np.newaxis].reshape(test_df.shape[0],-1)\n","test_label = test_df['label'].tolist()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6MGKzKb7mHFE","colab_type":"code","colab":{}},"source":["# tf.compat.v1.experimental.output_all_intermediates(True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"lO8xmZ4R4CUc","colab_type":"code","outputId":"3d322e65-9e3c-4a85-ed75-26a126719b95","executionInfo":{"status":"error","timestamp":1588960121333,"user_tz":-270,"elapsed":2513636,"user":{"displayName":"Aref Afzali","photoUrl":"","userId":"04593065310074929856"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["  # def variable_created_in_scope(self, v):\n","  #   if not hasattr(v, '_distribute_strategy'):\n","  #     v._distribute_strategy = None\n","  #   return v._distribute_strategy is None  # pylint: disable=protected-access\n","#==============================================================================================\n","metrics = Metrics(([test_ids, test_masks, np.zeros(test_ids.shape)], test_label))\n","\n","model.fit([train_ids, train_masks, np.zeros(train_ids.shape)], \n","          train_label,\n","          validation_data=([test_ids, test_masks, np.zeros(test_ids.shape)], test_label),\n","          epochs=50,\n","          callbacks=[metrics],\n","          batch_size=32)"],"execution_count":13,"outputs":[{"output_type":"stream","text":["Train on 4568 samples, validate on 1004 samples\n","Epoch 1/50\n","4568/4568 [==============================] - 111s 24ms/sample - loss: 0.1581 - accuracy: 0.9532 - val_loss: 0.0939 - val_accuracy: 0.9801\n","Epoch 2/50\n","4568/4568 [==============================] - 113s 25ms/sample - loss: 0.1145 - accuracy: 0.9713 - val_loss: 0.1950 - val_accuracy: 0.9612\n","Epoch 3/50\n","4568/4568 [==============================] - 113s 25ms/sample - loss: 0.4455 - accuracy: 0.8430 - val_loss: 0.4379 - val_accuracy: 0.8416\n","Epoch 4/50\n","4568/4568 [==============================] - 113s 25ms/sample - loss: 0.2889 - accuracy: 0.9081 - val_loss: 0.4372 - val_accuracy: 0.8416\n","Epoch 5/50\n","4568/4568 [==============================] - 113s 25ms/sample - loss: 0.3863 - accuracy: 0.8713 - val_loss: 0.4568 - val_accuracy: 0.8416\n","Epoch 6/50\n","4568/4568 [==============================] - 113s 25ms/sample - loss: 0.3863 - accuracy: 0.8713 - val_loss: 0.4410 - val_accuracy: 0.8416\n","Epoch 7/50\n","4568/4568 [==============================] - 113s 25ms/sample - loss: 0.3834 - accuracy: 0.8713 - val_loss: 0.4386 - val_accuracy: 0.8416\n","Epoch 8/50\n","4568/4568 [==============================] - 112s 25ms/sample - loss: 0.3859 - accuracy: 0.8713 - val_loss: 0.4428 - val_accuracy: 0.8416\n","Epoch 9/50\n","4568/4568 [==============================] - 112s 25ms/sample - loss: 0.3865 - accuracy: 0.8713 - val_loss: 0.4384 - val_accuracy: 0.8416\n","Epoch 10/50\n","4568/4568 [==============================] - 112s 25ms/sample - loss: 0.3877 - accuracy: 0.8713 - val_loss: 0.4483 - val_accuracy: 0.8416\n","Epoch 11/50\n","4568/4568 [==============================] - 112s 25ms/sample - loss: 0.3859 - accuracy: 0.8713 - val_loss: 0.4435 - val_accuracy: 0.8416\n","Epoch 12/50\n","4568/4568 [==============================] - 112s 25ms/sample - loss: 0.3848 - accuracy: 0.8713 - val_loss: 0.4553 - val_accuracy: 0.8416\n","Epoch 13/50\n","4568/4568 [==============================] - 112s 25ms/sample - loss: 0.3874 - accuracy: 0.8713 - val_loss: 0.4428 - val_accuracy: 0.8416\n","Epoch 14/50\n","4568/4568 [==============================] - 112s 25ms/sample - loss: 0.3861 - accuracy: 0.8713 - val_loss: 0.4372 - val_accuracy: 0.8416\n","Epoch 15/50\n","4568/4568 [==============================] - 112s 25ms/sample - loss: 0.3856 - accuracy: 0.8713 - val_loss: 0.4521 - val_accuracy: 0.8416\n","Epoch 16/50\n","4568/4568 [==============================] - 112s 25ms/sample - loss: 0.3854 - accuracy: 0.8713 - val_loss: 0.4458 - val_accuracy: 0.8416\n","Epoch 17/50\n","4568/4568 [==============================] - 112s 25ms/sample - loss: 0.3856 - accuracy: 0.8713 - val_loss: 0.4389 - val_accuracy: 0.8416\n","Epoch 18/50\n","4568/4568 [==============================] - 112s 25ms/sample - loss: 0.3855 - accuracy: 0.8713 - val_loss: 0.4371 - val_accuracy: 0.8416\n","Epoch 19/50\n","4568/4568 [==============================] - 112s 25ms/sample - loss: 0.3855 - accuracy: 0.8713 - val_loss: 0.4608 - val_accuracy: 0.8416\n","Epoch 20/50\n","4568/4568 [==============================] - 112s 25ms/sample - loss: 0.3861 - accuracy: 0.8713 - val_loss: 0.4387 - val_accuracy: 0.8416\n","Epoch 21/50\n","4568/4568 [==============================] - 112s 25ms/sample - loss: 0.3858 - accuracy: 0.8713 - val_loss: 0.4400 - val_accuracy: 0.8416\n","Epoch 22/50\n","4568/4568 [==============================] - ETA: 0s - loss: 0.3869 - accuracy: 0.8713"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-13-052a9c842a75>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m           \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m           batch_size=32)\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_v1.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    783\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    784\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 785\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    786\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    787\u001b[0m   def evaluate(self,\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    664\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    665\u001b[0m         \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 666\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    667\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m   def evaluate(self,\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    429\u001b[0m           \u001b[0mvalidation_in_fit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m           \u001b[0mprepared_feed_values_from_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 431\u001b[0;31m           steps_name='validation_steps')\n\u001b[0m\u001b[1;32m    432\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_results\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0mval_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mval_results\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 386\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    387\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3630\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3631\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3632\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3633\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3634\u001b[0m     output_structure = nest.pack_sequence_as(\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"-4iyUZU_lYu7","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}